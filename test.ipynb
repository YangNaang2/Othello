{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오델로 강화학습\n",
    "\n",
    "**주요 기능**\n",
    "- Gym 인터페이스를 통한 오델로 환경 상호작용 \n",
    "- human vs cpu , human vs human, cpu vs cpu 시뮬레이션 기능\n",
    "  \n",
    "**테스트 코드 요약**\n",
    "\n",
    "1. Dqn + Greedy Policy learning\n",
    "2. DQN + UCT Policy learning\n",
    "3. DQN + UCT Policy + DQN + UCT Policy 경쟁 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_games\n",
    "import gymnasium as gym\n",
    "from DeepQResNet import DQN\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "env = gym.make('Othello-v0',render_mode='human')\n",
    "state_shape = (8, 8, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dqn + Greedy Policy learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.metadata['autoplay'] = True\n",
    "env.metadata['render_fps'] = 1000000\n",
    "\n",
    "\n",
    "obs, reward, bdone, _, info = env.reset()\n",
    "dqn = DQN(state_shape,env.action_space.n)\n",
    "version = -1\n",
    "#dqn.load( f\"model/Greedy/BlackModel_{version}.weights.h5\")\n",
    "count = version +1\n",
    "def GetPolicy(bdone,wdone,turn,obs,actions):\n",
    "    if(not actions):\n",
    "        return None\n",
    "    if(turn==1):\n",
    "        if(bdone):\n",
    "            return None\n",
    "    else:\n",
    "        if(wdone):\n",
    "            return None\n",
    "    return dqn.EstimatePolicy(obs,turn,actions)\n",
    "def InsertBuffer(turn,oldobs, action, reward,obs,done,actions):\n",
    "    dqn.InsertBuffer(oldobs, action, reward,obs,done,actions,turn)\n",
    "\n",
    "for episode in range(1,500):\n",
    "    bdone = False\n",
    "    wdone = False\n",
    "    obs, reward, done, _, info = env.reset()\n",
    "    steps = 0\n",
    "    while (not bdone) or (not wdone):\n",
    "        actions = info['action']\n",
    "        turn = info['turn']\n",
    "        oldobs = obs\n",
    "        action = GetPolicy(bdone,wdone,turn,obs,actions)\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        if done:\n",
    "            if info['turn'] ==2:\n",
    "                wdone = True\n",
    "            else:\n",
    "                bdone = True\n",
    "        if(action is not None):\n",
    "            InsertBuffer(turn,oldobs, action, reward,obs,done,info['action'])\n",
    "        steps += 1\n",
    "    loss = dqn.train()\n",
    "    if loss is not None:\n",
    "        print(f\"Episode {episode + 1},=Loss: {loss}\\n\")\n",
    "    if(episode % 30 == 0):\n",
    "        print(\"update Target Model\")\n",
    "        dqn.update_target_model()\n",
    "    if(episode % 100 == 0):\n",
    "        print('save \\n')\n",
    "        dqn.save(f\"model/Greedy/Model_{count}.weights.h5\")\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN + UCT Policy learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env.metadata['autoplay'] = True\n",
    "env.metadata['render_fps'] = 1500000\n",
    "obs, reward, bdone, _, info = env.reset()\n",
    "dqn = DQN(state_shape,env.action_space.n)\n",
    "\n",
    "version = -1\n",
    "#dqn.load( f\"model/UCT/Model_{version}.weights.h5\")\n",
    "Count = version +1\n",
    "def GetPolicy(bdone,wdone,turn,env,obs,actions):\n",
    "    if(not actions):\n",
    "        return None\n",
    "    if(turn==1):\n",
    "        if(bdone):\n",
    "            return None\n",
    "    else:\n",
    "        if(wdone):\n",
    "            return None\n",
    "    return dqn.BehaviorPolicy(env,obs,turn,actions)\n",
    "def InsertBuffer(turn,oldobs, action, reward,obs,done,actions):\n",
    "    dqn.InsertBuffer(oldobs, action, reward,obs,done,actions,turn)\n",
    "for episode in range(1,400):\n",
    "    bdone = False\n",
    "    wdone = False\n",
    "    obs, reward, done, _, info = env.reset()\n",
    "    steps = 0\n",
    "    while (not bdone) or (not wdone):\n",
    "        actions = info['action']\n",
    "        turn = info['turn']\n",
    "        oldobs = obs\n",
    "        action = GetPolicy(bdone,wdone,turn,env,obs,actions)\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        if done:\n",
    "            if info['turn'] ==2:\n",
    "                wdone = True\n",
    "            else:\n",
    "                bdone = True\n",
    "        if(action is not None):\n",
    "            InsertBuffer(turn,oldobs, action, reward,obs,done,actions)\n",
    "        steps += 1\n",
    "    loss = dqn.train()\n",
    "    if loss is not None:\n",
    "        print(f\"Episode {episode + 1}, Loss: {loss}\\n\")\n",
    "    if(episode % 30 == 0):\n",
    "        print(\"update Target Model\")\n",
    "        dqn.update_target_model()\n",
    "    if(episode % 100 == 0):\n",
    "        print('save ')\n",
    "        dqn.save(f\"model/UCT/Model_{Count}.weights.h5\")\n",
    "        Count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경쟁 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4, BlackLoss: 1.614793300628662\n",
      "\n",
      "Episode 4, WhiteLoss: 1.7577934265136719\n",
      "\n",
      "Episode 6, BlackLoss: 1.349267601966858\n",
      "\n",
      "Episode 6, WhiteLoss: 1.512926697731018\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001534307C2C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001534037C040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Episode 8, BlackLoss: 1.1248804330825806\n",
      "\n",
      "Episode 8, WhiteLoss: 1.2767577171325684\n",
      "\n",
      "Episode 10, BlackLoss: 0.9338687658309937\n",
      "\n",
      "Episode 10, WhiteLoss: 1.0718914270401\n",
      "\n",
      "Episode 12, BlackLoss: 0.7854718565940857\n",
      "\n",
      "Episode 12, WhiteLoss: 0.9076473116874695\n",
      "\n",
      "Episode 14, BlackLoss: 0.6724572777748108\n",
      "\n",
      "Episode 14, WhiteLoss: 0.7806628346443176\n",
      "\n",
      "Episode 16, BlackLoss: 0.5856212973594666\n",
      "\n",
      "Episode 16, WhiteLoss: 0.6815481781959534\n",
      "\n",
      "Episode 19, BlackLoss: 0.5188606977462769\n",
      "\n",
      "Episode 19, WhiteLoss: 0.6032830476760864\n",
      "\n",
      "Episode 21, BlackLoss: 0.46567270159721375\n",
      "\n",
      "Episode 21, WhiteLoss: 0.5406937003135681\n",
      "\n",
      "Episode 23, BlackLoss: 0.4225471615791321\n",
      "\n",
      "Episode 23, WhiteLoss: 0.4898558557033539\n",
      "\n",
      "Episode 25, BlackLoss: 0.3868508040904999\n",
      "\n",
      "Episode 25, WhiteLoss: 0.4479089677333832\n",
      "\n",
      "Episode 27, BlackLoss: 0.35697707533836365\n",
      "\n",
      "Episode 27, WhiteLoss: 0.4129396677017212\n",
      "\n",
      "Episode 29, BlackLoss: 0.33184462785720825\n",
      "\n",
      "Episode 29, WhiteLoss: 0.38327041268348694\n",
      "\n",
      "Episode 31, BlackLoss: 0.30983591079711914\n",
      "\n",
      "Episode 31, WhiteLoss: 0.35805264115333557\n",
      "\n",
      "update Target Model\n",
      "Episode 34, BlackLoss: 0.29084286093711853\n",
      "\n",
      "Episode 34, WhiteLoss: 0.3359762132167816\n",
      "\n",
      "Episode 36, BlackLoss: 0.2741750478744507\n",
      "\n",
      "Episode 36, WhiteLoss: 0.31666168570518494\n",
      "\n",
      "Episode 38, BlackLoss: 0.25953805446624756\n",
      "\n",
      "Episode 38, WhiteLoss: 0.299524188041687\n",
      "\n",
      "Episode 40, BlackLoss: 0.2466568946838379\n",
      "\n",
      "Episode 40, WhiteLoss: 0.28410059213638306\n",
      "\n",
      "Episode 42, BlackLoss: 0.23502106964588165\n",
      "\n",
      "Episode 42, WhiteLoss: 0.27015963196754456\n",
      "\n",
      "Episode 44, BlackLoss: 0.2245093137025833\n",
      "\n",
      "Episode 44, WhiteLoss: 0.2575133144855499\n",
      "\n",
      "Episode 46, BlackLoss: 0.21506278216838837\n",
      "\n",
      "Episode 46, WhiteLoss: 0.24595721065998077\n",
      "\n",
      "Episode 48, BlackLoss: 0.2066146284341812\n",
      "\n",
      "Episode 48, WhiteLoss: 0.23532269895076752\n",
      "\n",
      "Episode 51, BlackLoss: 0.19902701675891876\n",
      "\n",
      "Episode 51, WhiteLoss: 0.22554995119571686\n",
      "\n",
      "Episode 53, BlackLoss: 0.19198483228683472\n",
      "\n",
      "Episode 53, WhiteLoss: 0.21656382083892822\n",
      "\n",
      "Episode 55, BlackLoss: 0.18581824004650116\n",
      "\n",
      "Episode 55, WhiteLoss: 0.20830707252025604\n",
      "\n",
      "Episode 57, BlackLoss: 0.18015091121196747\n",
      "\n",
      "Episode 57, WhiteLoss: 0.20062778890132904\n",
      "\n",
      "Episode 59, BlackLoss: 0.17497625946998596\n",
      "\n",
      "Episode 59, WhiteLoss: 0.1935187131166458\n",
      "\n",
      "Episode 61, BlackLoss: 0.16997189819812775\n",
      "\n",
      "Episode 61, WhiteLoss: 0.1868899166584015\n",
      "\n",
      "update Target Model\n",
      "Episode 63, BlackLoss: 0.1654573380947113\n",
      "\n",
      "Episode 63, WhiteLoss: 0.18074741959571838\n",
      "\n",
      "Episode 66, BlackLoss: 0.16164012253284454\n",
      "\n",
      "Episode 66, WhiteLoss: 0.1750335991382599\n",
      "\n",
      "Episode 68, BlackLoss: 0.15809020400047302\n",
      "\n",
      "Episode 68, WhiteLoss: 0.16969558596611023\n",
      "\n",
      "Episode 70, BlackLoss: 0.15475541353225708\n",
      "\n",
      "Episode 70, WhiteLoss: 0.16471076011657715\n",
      "\n",
      "Episode 72, BlackLoss: 0.1515662670135498\n",
      "\n",
      "Episode 72, WhiteLoss: 0.16011008620262146\n",
      "\n",
      "Episode 74, BlackLoss: 0.14864306151866913\n",
      "\n",
      "Episode 74, WhiteLoss: 0.15576615929603577\n",
      "\n",
      "Episode 76, BlackLoss: 0.14566722512245178\n",
      "\n",
      "Episode 76, WhiteLoss: 0.15160562098026276\n",
      "\n",
      "Episode 78, BlackLoss: 0.14294075965881348\n",
      "\n",
      "Episode 78, WhiteLoss: 0.1477113664150238\n",
      "\n",
      "Episode 80, BlackLoss: 0.13998061418533325\n",
      "\n",
      "Episode 80, WhiteLoss: 0.14398150146007538\n",
      "\n",
      "Episode 83, BlackLoss: 0.1374083310365677\n",
      "\n",
      "Episode 83, WhiteLoss: 0.1404707431793213\n",
      "\n",
      "Episode 85, BlackLoss: 0.1350293606519699\n",
      "\n",
      "Episode 85, WhiteLoss: 0.13714733719825745\n",
      "\n",
      "Episode 87, BlackLoss: 0.13311246037483215\n",
      "\n",
      "Episode 87, WhiteLoss: 0.13396641612052917\n",
      "\n",
      "Episode 89, BlackLoss: 0.13139444589614868\n",
      "\n",
      "Episode 89, WhiteLoss: 0.13091547787189484\n",
      "\n",
      "Episode 91, BlackLoss: 0.12958146631717682\n",
      "\n",
      "Episode 91, WhiteLoss: 0.12803395092487335\n",
      "\n",
      "update Target Model\n",
      "Episode 93, BlackLoss: 0.12784327566623688\n",
      "\n",
      "Episode 93, WhiteLoss: 0.1252770870923996\n",
      "\n",
      "Episode 95, BlackLoss: 0.12589848041534424\n",
      "\n",
      "Episode 95, WhiteLoss: 0.12262043356895447\n",
      "\n",
      "Episode 98, BlackLoss: 0.12423781305551529\n",
      "\n",
      "Episode 98, WhiteLoss: 0.12008461356163025\n",
      "\n",
      "Episode 100, BlackLoss: 0.12261214107275009\n",
      "\n",
      "Episode 100, WhiteLoss: 0.11765353381633759\n",
      "\n",
      "save \n",
      "Episode 103, BlackLoss: 0.1211438775062561\n",
      "\n",
      "Episode 103, WhiteLoss: 0.11532337218523026\n",
      "\n",
      "Episode 105, BlackLoss: 0.11991992592811584\n",
      "\n",
      "Episode 105, WhiteLoss: 0.11308461427688599\n",
      "\n",
      "Episode 107, BlackLoss: 0.11843394488096237\n",
      "\n",
      "Episode 107, WhiteLoss: 0.11093144863843918\n",
      "\n",
      "Episode 109, BlackLoss: 0.11704881489276886\n",
      "\n",
      "Episode 109, WhiteLoss: 0.10883498191833496\n",
      "\n",
      "Episode 111, BlackLoss: 0.115735724568367\n",
      "\n",
      "Episode 111, WhiteLoss: 0.10682087391614914\n",
      "\n",
      "Episode 113, BlackLoss: 0.11450660973787308\n",
      "\n",
      "Episode 113, WhiteLoss: 0.10489972680807114\n",
      "\n",
      "Episode 115, BlackLoss: 0.11327391862869263\n",
      "\n",
      "Episode 115, WhiteLoss: 0.10304073244333267\n",
      "\n",
      "Episode 117, BlackLoss: 0.11204395443201065\n",
      "\n",
      "Episode 117, WhiteLoss: 0.10124444961547852\n",
      "\n",
      "Episode 120, BlackLoss: 0.1108541265130043\n",
      "\n",
      "Episode 120, WhiteLoss: 0.09949774295091629\n",
      "\n",
      "update Target Model\n",
      "Episode 122, BlackLoss: 0.10973214358091354\n",
      "\n",
      "Episode 122, WhiteLoss: 0.09783972054719925\n",
      "\n",
      "Episode 124, BlackLoss: 0.10869383066892624\n",
      "\n",
      "Episode 124, WhiteLoss: 0.09623085707426071\n",
      "\n",
      "Episode 126, BlackLoss: 0.10763455182313919\n",
      "\n",
      "Episode 126, WhiteLoss: 0.09466536343097687\n",
      "\n",
      "Episode 128, BlackLoss: 0.10660260915756226\n",
      "\n",
      "Episode 128, WhiteLoss: 0.09315129369497299\n",
      "\n",
      "Episode 130, BlackLoss: 0.10571219772100449\n",
      "\n",
      "Episode 130, WhiteLoss: 0.0916862040758133\n",
      "\n",
      "Episode 132, BlackLoss: 0.1048920750617981\n",
      "\n",
      "Episode 132, WhiteLoss: 0.09026139229536057\n",
      "\n",
      "Episode 135, BlackLoss: 0.10412544012069702\n",
      "\n",
      "Episode 135, WhiteLoss: 0.08888313919305801\n",
      "\n",
      "Episode 137, BlackLoss: 0.10339420288801193\n",
      "\n",
      "Episode 137, WhiteLoss: 0.08756043761968613\n",
      "\n",
      "Episode 139, BlackLoss: 0.10273835808038712\n",
      "\n",
      "Episode 139, WhiteLoss: 0.08627792447805405\n",
      "\n",
      "Episode 141, BlackLoss: 0.10206593573093414\n",
      "\n",
      "Episode 141, WhiteLoss: 0.0850350484251976\n",
      "\n",
      "Episode 143, BlackLoss: 0.10135944932699203\n",
      "\n",
      "Episode 143, WhiteLoss: 0.08382288366556168\n",
      "\n",
      "Episode 145, BlackLoss: 0.1007189229130745\n",
      "\n",
      "Episode 145, WhiteLoss: 0.08265116810798645\n",
      "\n",
      "Episode 147, BlackLoss: 0.10007944703102112\n",
      "\n",
      "Episode 147, WhiteLoss: 0.08151520043611526\n",
      "\n",
      "Episode 150, BlackLoss: 0.09936901926994324\n",
      "\n",
      "Episode 150, WhiteLoss: 0.08040034770965576\n",
      "\n",
      "update Target Model\n",
      "Episode 152, BlackLoss: 0.09865846484899521\n",
      "\n",
      "Episode 152, WhiteLoss: 0.07932069152593613\n",
      "\n",
      "Episode 154, BlackLoss: 0.09801872074604034\n",
      "\n",
      "Episode 154, WhiteLoss: 0.0782603994011879\n",
      "\n",
      "Episode 156, BlackLoss: 0.097450390458107\n",
      "\n",
      "Episode 156, WhiteLoss: 0.07724029570817947\n",
      "\n",
      "Episode 158, BlackLoss: 0.0969771295785904\n",
      "\n",
      "Episode 158, WhiteLoss: 0.07625453174114227\n",
      "\n",
      "Episode 160, BlackLoss: 0.09650404751300812\n",
      "\n",
      "Episode 160, WhiteLoss: 0.07528778165578842\n",
      "\n",
      "Episode 162, BlackLoss: 0.09607572853565216\n",
      "\n",
      "Episode 162, WhiteLoss: 0.0743461325764656\n",
      "\n",
      "Episode 164, BlackLoss: 0.09565822780132294\n",
      "\n",
      "Episode 164, WhiteLoss: 0.07342077791690826\n",
      "\n",
      "Episode 167, BlackLoss: 0.09533710032701492\n",
      "\n",
      "Episode 167, WhiteLoss: 0.07252544909715652\n",
      "\n",
      "Episode 169, BlackLoss: 0.09493061155080795\n",
      "\n",
      "Episode 169, WhiteLoss: 0.07164880633354187\n",
      "\n",
      "Episode 171, BlackLoss: 0.09445091336965561\n",
      "\n",
      "Episode 171, WhiteLoss: 0.0708065927028656\n",
      "\n",
      "Episode 173, BlackLoss: 0.09390068054199219\n",
      "\n",
      "Episode 173, WhiteLoss: 0.06996850669384003\n",
      "\n",
      "Episode 175, BlackLoss: 0.09335125237703323\n",
      "\n",
      "Episode 175, WhiteLoss: 0.06915796548128128\n",
      "\n",
      "Episode 177, BlackLoss: 0.09276074171066284\n",
      "\n",
      "Episode 177, WhiteLoss: 0.06836393475532532\n",
      "\n",
      "Episode 179, BlackLoss: 0.09206529706716537\n",
      "\n",
      "Episode 179, WhiteLoss: 0.06759733706712723\n",
      "\n",
      "update Target Model\n",
      "Episode 182, BlackLoss: 0.09134293347597122\n",
      "\n",
      "Episode 182, WhiteLoss: 0.0668407455086708\n",
      "\n",
      "Episode 184, BlackLoss: 0.09060397744178772\n",
      "\n",
      "Episode 184, WhiteLoss: 0.06611344963312149\n",
      "\n",
      "Episode 186, BlackLoss: 0.08992969989776611\n",
      "\n",
      "Episode 186, WhiteLoss: 0.06540151685476303\n",
      "\n",
      "Episode 188, BlackLoss: 0.08919699490070343\n",
      "\n",
      "Episode 188, WhiteLoss: 0.06470206379890442\n",
      "\n",
      "Episode 190, BlackLoss: 0.08849882334470749\n",
      "\n",
      "Episode 190, WhiteLoss: 0.06400779634714127\n",
      "\n",
      "Episode 192, BlackLoss: 0.08788272738456726\n",
      "\n",
      "Episode 192, WhiteLoss: 0.06333518028259277\n",
      "\n",
      "Episode 194, BlackLoss: 0.08723009377717972\n",
      "\n",
      "Episode 194, WhiteLoss: 0.06267710030078888\n",
      "\n",
      "Episode 197, BlackLoss: 0.08655433356761932\n",
      "\n",
      "Episode 197, WhiteLoss: 0.06203388795256615\n",
      "\n",
      "Episode 199, BlackLoss: 0.08591191470623016\n",
      "\n",
      "Episode 199, WhiteLoss: 0.06140650436282158\n",
      "\n",
      "Episode 201, BlackLoss: 0.0853155329823494\n",
      "\n",
      "Episode 201, WhiteLoss: 0.060788169503211975\n",
      "\n",
      "save \n",
      "Episode 203, BlackLoss: 0.08475834131240845\n",
      "\n",
      "Episode 203, WhiteLoss: 0.060179710388183594\n",
      "\n",
      "Episode 205, BlackLoss: 0.08414284884929657\n",
      "\n",
      "Episode 205, WhiteLoss: 0.0595884807407856\n",
      "\n",
      "Episode 207, BlackLoss: 0.08359896391630173\n",
      "\n",
      "Episode 207, WhiteLoss: 0.05900708958506584\n",
      "\n",
      "Episode 209, BlackLoss: 0.08297663927078247\n",
      "\n",
      "Episode 209, WhiteLoss: 0.058446627110242844\n",
      "\n",
      "update Target Model\n",
      "Episode 212, BlackLoss: 0.08238711953163147\n",
      "\n",
      "Episode 212, WhiteLoss: 0.05788922309875488\n",
      "\n",
      "Episode 214, BlackLoss: 0.0818055272102356\n",
      "\n",
      "Episode 214, WhiteLoss: 0.05734851211309433\n",
      "\n",
      "Episode 216, BlackLoss: 0.08125189691781998\n",
      "\n",
      "Episode 216, WhiteLoss: 0.056814052164554596\n",
      "\n",
      "Episode 218, BlackLoss: 0.08074942976236343\n",
      "\n",
      "Episode 218, WhiteLoss: 0.056297071278095245\n",
      "\n",
      "Episode 220, BlackLoss: 0.08017408847808838\n",
      "\n",
      "Episode 220, WhiteLoss: 0.055783145129680634\n",
      "\n",
      "Episode 222, BlackLoss: 0.07965525984764099\n",
      "\n",
      "Episode 222, WhiteLoss: 0.05527961626648903\n",
      "\n",
      "Episode 224, BlackLoss: 0.07912805676460266\n",
      "\n",
      "Episode 224, WhiteLoss: 0.05479098856449127\n",
      "\n",
      "Episode 226, BlackLoss: 0.07858645170927048\n",
      "\n",
      "Episode 226, WhiteLoss: 0.054305948317050934\n",
      "\n",
      "Episode 229, BlackLoss: 0.07803169637918472\n",
      "\n",
      "Episode 229, WhiteLoss: 0.05382532998919487\n",
      "\n",
      "Episode 231, BlackLoss: 0.0775097981095314\n",
      "\n",
      "Episode 231, WhiteLoss: 0.05335749685764313\n",
      "\n",
      "Episode 233, BlackLoss: 0.07696592062711716\n",
      "\n",
      "Episode 233, WhiteLoss: 0.05289572849869728\n",
      "\n",
      "Episode 235, BlackLoss: 0.07642702013254166\n",
      "\n",
      "Episode 235, WhiteLoss: 0.05244610831141472\n",
      "\n",
      "Episode 237, BlackLoss: 0.0758955329656601\n",
      "\n",
      "Episode 237, WhiteLoss: 0.05200910195708275\n",
      "\n",
      "Episode 239, BlackLoss: 0.07535664737224579\n",
      "\n",
      "Episode 239, WhiteLoss: 0.05157328024506569\n",
      "\n",
      "Episode 241, BlackLoss: 0.07481609284877777\n",
      "\n",
      "Episode 241, WhiteLoss: 0.05114525929093361\n",
      "\n",
      "update Target Model\n",
      "Episode 244, BlackLoss: 0.0742981806397438\n",
      "\n",
      "Episode 244, WhiteLoss: 0.0507282018661499\n",
      "\n",
      "Episode 246, BlackLoss: 0.0737718716263771\n",
      "\n",
      "Episode 246, WhiteLoss: 0.05032056197524071\n",
      "\n",
      "Episode 248, BlackLoss: 0.07327672094106674\n",
      "\n",
      "Episode 248, WhiteLoss: 0.04992443323135376\n",
      "\n",
      "Episode 250, BlackLoss: 0.07276638597249985\n",
      "\n",
      "Episode 250, WhiteLoss: 0.04952956736087799\n",
      "\n",
      "Episode 252, BlackLoss: 0.07225722819566727\n",
      "\n",
      "Episode 252, WhiteLoss: 0.04913879185914993\n",
      "\n",
      "Episode 254, BlackLoss: 0.07179656624794006\n",
      "\n",
      "Episode 254, WhiteLoss: 0.04875066876411438\n",
      "\n",
      "Episode 256, BlackLoss: 0.07131732255220413\n",
      "\n",
      "Episode 256, WhiteLoss: 0.04838457331061363\n",
      "\n",
      "Episode 259, BlackLoss: 0.07085313647985458\n",
      "\n",
      "Episode 259, WhiteLoss: 0.04801275581121445\n",
      "\n",
      "Episode 261, BlackLoss: 0.07038258761167526\n",
      "\n",
      "Episode 261, WhiteLoss: 0.04764421284198761\n",
      "\n",
      "Episode 263, BlackLoss: 0.06990773230791092\n",
      "\n",
      "Episode 263, WhiteLoss: 0.0472850538790226\n",
      "\n",
      "Episode 265, BlackLoss: 0.06944037973880768\n",
      "\n",
      "Episode 265, WhiteLoss: 0.04693405702710152\n",
      "\n",
      "Episode 267, BlackLoss: 0.06899808347225189\n",
      "\n",
      "Episode 267, WhiteLoss: 0.04658946394920349\n",
      "\n",
      "Episode 269, BlackLoss: 0.06856489926576614\n",
      "\n",
      "Episode 269, WhiteLoss: 0.046249520033597946\n",
      "\n",
      "Episode 271, BlackLoss: 0.0681127980351448\n",
      "\n",
      "Episode 271, WhiteLoss: 0.04591194912791252\n",
      "\n",
      "update Target Model\n",
      "Episode 274, BlackLoss: 0.06768336147069931\n",
      "\n",
      "Episode 274, WhiteLoss: 0.045582469552755356\n",
      "\n",
      "Episode 276, BlackLoss: 0.06726521998643875\n",
      "\n",
      "Episode 276, WhiteLoss: 0.04525784030556679\n",
      "\n",
      "Episode 278, BlackLoss: 0.0668485164642334\n",
      "\n",
      "Episode 278, WhiteLoss: 0.04494104161858559\n",
      "\n",
      "Episode 280, BlackLoss: 0.0664408802986145\n",
      "\n",
      "Episode 280, WhiteLoss: 0.044629212468862534\n",
      "\n",
      "Episode 282, BlackLoss: 0.06602431833744049\n",
      "\n",
      "Episode 282, WhiteLoss: 0.044319868087768555\n",
      "\n",
      "Episode 284, BlackLoss: 0.06562268733978271\n",
      "\n",
      "Episode 284, WhiteLoss: 0.04401553049683571\n",
      "\n",
      "Episode 286, BlackLoss: 0.0652068555355072\n",
      "\n",
      "Episode 286, WhiteLoss: 0.043711163103580475\n",
      "\n",
      "Episode 288, BlackLoss: 0.06480630487203598\n",
      "\n",
      "Episode 288, WhiteLoss: 0.043418485671281815\n",
      "\n",
      "Episode 291, BlackLoss: 0.06441445648670197\n",
      "\n",
      "Episode 291, WhiteLoss: 0.043128352612257004\n",
      "\n",
      "Episode 293, BlackLoss: 0.06401050090789795\n",
      "\n",
      "Episode 293, WhiteLoss: 0.04284118860960007\n",
      "\n",
      "Episode 295, BlackLoss: 0.0636022612452507\n",
      "\n",
      "Episode 295, WhiteLoss: 0.04255621135234833\n",
      "\n",
      "Episode 297, BlackLoss: 0.06322290748357773\n",
      "\n",
      "Episode 297, WhiteLoss: 0.042276397347450256\n",
      "\n",
      "Episode 299, BlackLoss: 0.06283335387706757\n",
      "\n",
      "Episode 299, WhiteLoss: 0.042002685368061066\n",
      "\n",
      "Episode 301, BlackLoss: 0.06245405226945877\n",
      "\n",
      "Episode 301, WhiteLoss: 0.04173072800040245\n",
      "\n",
      "update Target Model\n",
      "save \n",
      "Episode 303, BlackLoss: 0.06206725537776947\n",
      "\n",
      "Episode 303, WhiteLoss: 0.04146706312894821\n",
      "\n",
      "Episode 306, BlackLoss: 0.06168669834733009\n",
      "\n",
      "Episode 306, WhiteLoss: 0.04120752960443497\n",
      "\n",
      "Episode 308, BlackLoss: 0.06132178381085396\n",
      "\n",
      "Episode 308, WhiteLoss: 0.04094984009861946\n",
      "\n",
      "Episode 310, BlackLoss: 0.06095431372523308\n",
      "\n",
      "Episode 310, WhiteLoss: 0.04069212079048157\n",
      "\n",
      "Episode 312, BlackLoss: 0.060591861605644226\n",
      "\n",
      "Episode 312, WhiteLoss: 0.04043786972761154\n",
      "\n",
      "Episode 314, BlackLoss: 0.06022550165653229\n",
      "\n",
      "Episode 314, WhiteLoss: 0.040185220539569855\n",
      "\n",
      "Episode 316, BlackLoss: 0.05987223982810974\n",
      "\n",
      "Episode 316, WhiteLoss: 0.03993692994117737\n",
      "\n",
      "Episode 318, BlackLoss: 0.059511661529541016\n",
      "\n",
      "Episode 318, WhiteLoss: 0.03969539701938629\n",
      "\n",
      "Episode 321, BlackLoss: 0.05915488302707672\n",
      "\n",
      "Episode 321, WhiteLoss: 0.03945736214518547\n",
      "\n",
      "Episode 323, BlackLoss: 0.05882326140999794\n",
      "\n",
      "Episode 323, WhiteLoss: 0.03922415152192116\n",
      "\n",
      "Episode 325, BlackLoss: 0.05848875269293785\n",
      "\n",
      "Episode 325, WhiteLoss: 0.03899413347244263\n",
      "\n",
      "Episode 327, BlackLoss: 0.05815742537379265\n",
      "\n",
      "Episode 327, WhiteLoss: 0.038764744997024536\n",
      "\n",
      "Episode 329, BlackLoss: 0.057821691036224365\n",
      "\n",
      "Episode 329, WhiteLoss: 0.03853663429617882\n",
      "\n",
      "Episode 331, BlackLoss: 0.057503100484609604\n",
      "\n",
      "Episode 331, WhiteLoss: 0.03831793740391731\n",
      "\n",
      "update Target Model\n",
      "Episode 333, BlackLoss: 0.057184141129255295\n",
      "\n",
      "Episode 333, WhiteLoss: 0.03809880092740059\n",
      "\n",
      "Episode 335, BlackLoss: 0.05686544254422188\n",
      "\n",
      "Episode 335, WhiteLoss: 0.03788337484002113\n",
      "\n",
      "Episode 338, BlackLoss: 0.05656687170267105\n",
      "\n",
      "Episode 338, WhiteLoss: 0.037668272852897644\n",
      "\n",
      "Episode 340, BlackLoss: 0.05626533180475235\n",
      "\n",
      "Episode 340, WhiteLoss: 0.037461020052433014\n",
      "\n",
      "Episode 342, BlackLoss: 0.05595569312572479\n",
      "\n",
      "Episode 342, WhiteLoss: 0.03725419566035271\n",
      "\n",
      "Episode 345, BlackLoss: 0.05565137416124344\n",
      "\n",
      "Episode 345, WhiteLoss: 0.03704521805047989\n",
      "\n",
      "Episode 347, BlackLoss: 0.05534808337688446\n",
      "\n",
      "Episode 347, WhiteLoss: 0.03684169054031372\n",
      "\n",
      "Episode 349, BlackLoss: 0.05505882203578949\n",
      "\n",
      "Episode 349, WhiteLoss: 0.036637626588344574\n",
      "\n",
      "Episode 351, BlackLoss: 0.05476721003651619\n",
      "\n",
      "Episode 351, WhiteLoss: 0.036436524242162704\n",
      "\n",
      "Episode 353, BlackLoss: 0.054479166865348816\n",
      "\n",
      "Episode 353, WhiteLoss: 0.03624128922820091\n",
      "\n",
      "Episode 355, BlackLoss: 0.05419827625155449\n",
      "\n",
      "Episode 355, WhiteLoss: 0.036046940833330154\n",
      "\n",
      "Episode 357, BlackLoss: 0.053925514221191406\n",
      "\n",
      "Episode 357, WhiteLoss: 0.035854317247867584\n",
      "\n",
      "Episode 359, BlackLoss: 0.05365588143467903\n",
      "\n",
      "Episode 359, WhiteLoss: 0.03566696122288704\n",
      "\n",
      "update Target Model\n",
      "Episode 362, BlackLoss: 0.053372662514448166\n",
      "\n",
      "Episode 362, WhiteLoss: 0.035486023873090744\n",
      "\n",
      "Episode 364, BlackLoss: 0.05310210958123207\n",
      "\n",
      "Episode 364, WhiteLoss: 0.035307466983795166\n",
      "\n",
      "Episode 366, BlackLoss: 0.05283036082983017\n",
      "\n",
      "Episode 366, WhiteLoss: 0.03512951731681824\n",
      "\n",
      "Episode 368, BlackLoss: 0.05256155505776405\n",
      "\n",
      "Episode 368, WhiteLoss: 0.034951116889715195\n",
      "\n",
      "Episode 370, BlackLoss: 0.05229133740067482\n",
      "\n",
      "Episode 370, WhiteLoss: 0.03477155789732933\n",
      "\n",
      "Episode 372, BlackLoss: 0.052027806639671326\n",
      "\n",
      "Episode 372, WhiteLoss: 0.03459814935922623\n",
      "\n",
      "Episode 374, BlackLoss: 0.051780328154563904\n",
      "\n",
      "Episode 374, WhiteLoss: 0.03442859277129173\n",
      "\n",
      "Episode 377, BlackLoss: 0.05152638629078865\n",
      "\n",
      "Episode 377, WhiteLoss: 0.03425508365035057\n",
      "\n",
      "Episode 379, BlackLoss: 0.05126774683594704\n",
      "\n",
      "Episode 379, WhiteLoss: 0.03408991917967796\n",
      "\n",
      "Episode 381, BlackLoss: 0.05101874843239784\n",
      "\n",
      "Episode 381, WhiteLoss: 0.03392167389392853\n",
      "\n",
      "Episode 383, BlackLoss: 0.05077139660716057\n",
      "\n",
      "Episode 383, WhiteLoss: 0.03375203534960747\n",
      "\n",
      "Episode 385, BlackLoss: 0.05052580311894417\n",
      "\n",
      "Episode 385, WhiteLoss: 0.033587731420993805\n",
      "\n",
      "Episode 387, BlackLoss: 0.05027822032570839\n",
      "\n",
      "Episode 387, WhiteLoss: 0.03343037888407707\n",
      "\n",
      "Episode 389, BlackLoss: 0.05002867057919502\n",
      "\n",
      "Episode 389, WhiteLoss: 0.033268366008996964\n",
      "\n",
      "update Target Model\n",
      "Episode 392, BlackLoss: 0.04978657141327858\n",
      "\n",
      "Episode 392, WhiteLoss: 0.03311765566468239\n",
      "\n",
      "Episode 394, BlackLoss: 0.04954740032553673\n",
      "\n",
      "Episode 394, WhiteLoss: 0.0329575315117836\n",
      "\n",
      "Episode 396, BlackLoss: 0.04931240528821945\n",
      "\n",
      "Episode 396, WhiteLoss: 0.032804906368255615\n",
      "\n",
      "Episode 398, BlackLoss: 0.04907875508069992\n",
      "\n",
      "Episode 398, WhiteLoss: 0.032655853778123856\n",
      "\n",
      "Episode 400, BlackLoss: 0.04884319379925728\n",
      "\n",
      "Episode 400, WhiteLoss: 0.03250085562467575\n",
      "\n",
      "save \n",
      "Episode 402, BlackLoss: 0.04861783608794212\n",
      "\n",
      "Episode 402, WhiteLoss: 0.0323566235601902\n",
      "\n",
      "Episode 404, BlackLoss: 0.048392489552497864\n",
      "\n",
      "Episode 404, WhiteLoss: 0.0322091244161129\n",
      "\n",
      "Episode 407, BlackLoss: 0.04816022887825966\n",
      "\n",
      "Episode 407, WhiteLoss: 0.03206172212958336\n",
      "\n",
      "Episode 409, BlackLoss: 0.04793359711766243\n",
      "\n",
      "Episode 409, WhiteLoss: 0.03191845491528511\n",
      "\n",
      "Episode 411, BlackLoss: 0.04771511256694794\n",
      "\n",
      "Episode 411, WhiteLoss: 0.03177575394511223\n",
      "\n",
      "Episode 413, BlackLoss: 0.04750072583556175\n",
      "\n",
      "Episode 413, WhiteLoss: 0.031642038375139236\n",
      "\n",
      "Episode 415, BlackLoss: 0.047283656895160675\n",
      "\n",
      "Episode 415, WhiteLoss: 0.031508125364780426\n",
      "\n",
      "Episode 417, BlackLoss: 0.04707271605730057\n",
      "\n",
      "Episode 417, WhiteLoss: 0.03137163072824478\n",
      "\n",
      "Episode 419, BlackLoss: 0.04686513915657997\n",
      "\n",
      "Episode 419, WhiteLoss: 0.03123934008181095\n",
      "\n",
      "Episode 421, BlackLoss: 0.0466499961912632\n",
      "\n",
      "Episode 421, WhiteLoss: 0.031103437766432762\n",
      "\n",
      "update Target Model\n",
      "Episode 424, BlackLoss: 0.046443819999694824\n",
      "\n",
      "Episode 424, WhiteLoss: 0.030966736376285553\n",
      "\n",
      "Episode 426, BlackLoss: 0.046239107847213745\n",
      "\n",
      "Episode 426, WhiteLoss: 0.03083285503089428\n",
      "\n",
      "Episode 428, BlackLoss: 0.04603736847639084\n",
      "\n",
      "Episode 428, WhiteLoss: 0.030700484290719032\n",
      "\n",
      "Episode 430, BlackLoss: 0.04583566263318062\n",
      "\n",
      "Episode 430, WhiteLoss: 0.0305708646774292\n",
      "\n",
      "Episode 432, BlackLoss: 0.04564119130373001\n",
      "\n",
      "Episode 432, WhiteLoss: 0.030446277931332588\n",
      "\n",
      "Episode 434, BlackLoss: 0.04544439539313316\n",
      "\n",
      "Episode 434, WhiteLoss: 0.030321940779685974\n",
      "\n",
      "Episode 436, BlackLoss: 0.045261114835739136\n",
      "\n",
      "Episode 436, WhiteLoss: 0.030202461406588554\n",
      "\n",
      "Episode 439, BlackLoss: 0.04507214576005936\n",
      "\n",
      "Episode 439, WhiteLoss: 0.030079219490289688\n",
      "\n",
      "Episode 441, BlackLoss: 0.04488587751984596\n",
      "\n",
      "Episode 441, WhiteLoss: 0.02995690144598484\n",
      "\n",
      "Episode 443, BlackLoss: 0.04469989985227585\n",
      "\n",
      "Episode 443, WhiteLoss: 0.029835425317287445\n",
      "\n",
      "Episode 445, BlackLoss: 0.04451243579387665\n",
      "\n",
      "Episode 445, WhiteLoss: 0.02971610240638256\n",
      "\n",
      "Episode 447, BlackLoss: 0.04432743042707443\n",
      "\n",
      "Episode 447, WhiteLoss: 0.02959812991321087\n",
      "\n",
      "Episode 449, BlackLoss: 0.04413929581642151\n",
      "\n",
      "Episode 449, WhiteLoss: 0.029477767646312714\n",
      "\n",
      "Episode 451, BlackLoss: 0.043954044580459595\n",
      "\n",
      "Episode 451, WhiteLoss: 0.029358791187405586\n",
      "\n",
      "update Target Model\n",
      "Episode 454, BlackLoss: 0.043774090707302094\n",
      "\n",
      "Episode 454, WhiteLoss: 0.029239537194371223\n",
      "\n",
      "Episode 456, BlackLoss: 0.043594516813755035\n",
      "\n",
      "Episode 456, WhiteLoss: 0.0291256383061409\n",
      "\n",
      "Episode 458, BlackLoss: 0.04341369867324829\n",
      "\n",
      "Episode 458, WhiteLoss: 0.029009191319346428\n",
      "\n",
      "Episode 460, BlackLoss: 0.04323255270719528\n",
      "\n",
      "Episode 460, WhiteLoss: 0.02889440581202507\n",
      "\n",
      "Episode 462, BlackLoss: 0.0430532731115818\n",
      "\n",
      "Episode 462, WhiteLoss: 0.028781944885849953\n",
      "\n",
      "Episode 464, BlackLoss: 0.042879026383161545\n",
      "\n",
      "Episode 464, WhiteLoss: 0.028672723099589348\n",
      "\n",
      "Episode 466, BlackLoss: 0.04270699620246887\n",
      "\n",
      "Episode 466, WhiteLoss: 0.028561245650053024\n",
      "\n",
      "Episode 468, BlackLoss: 0.04254007712006569\n",
      "\n",
      "Episode 468, WhiteLoss: 0.028452642261981964\n",
      "\n",
      "Episode 471, BlackLoss: 0.042368292808532715\n",
      "\n",
      "Episode 471, WhiteLoss: 0.028348447754979134\n",
      "\n",
      "Episode 473, BlackLoss: 0.04219776764512062\n",
      "\n",
      "Episode 473, WhiteLoss: 0.028241539373993874\n",
      "\n",
      "Episode 475, BlackLoss: 0.042030707001686096\n",
      "\n",
      "Episode 475, WhiteLoss: 0.028140217065811157\n",
      "\n",
      "Episode 477, BlackLoss: 0.041862256824970245\n",
      "\n",
      "Episode 477, WhiteLoss: 0.028035596013069153\n",
      "\n",
      "Episode 479, BlackLoss: 0.04170102998614311\n",
      "\n",
      "Episode 479, WhiteLoss: 0.027932630851864815\n",
      "\n",
      "Episode 481, BlackLoss: 0.041536036878824234\n",
      "\n",
      "Episode 481, WhiteLoss: 0.027834726497530937\n",
      "\n",
      "update Target Model\n",
      "Episode 483, BlackLoss: 0.04137915000319481\n",
      "\n",
      "Episode 483, WhiteLoss: 0.027732471004128456\n",
      "\n",
      "Episode 486, BlackLoss: 0.04121645539999008\n",
      "\n",
      "Episode 486, WhiteLoss: 0.027630945667624474\n",
      "\n",
      "Episode 488, BlackLoss: 0.041060689836740494\n",
      "\n",
      "Episode 488, WhiteLoss: 0.027532687410712242\n",
      "\n",
      "Episode 491, BlackLoss: 0.04090724512934685\n",
      "\n",
      "Episode 491, WhiteLoss: 0.02743425965309143\n",
      "\n",
      "Episode 493, BlackLoss: 0.04075280576944351\n",
      "\n",
      "Episode 493, WhiteLoss: 0.027336524799466133\n",
      "\n",
      "Episode 495, BlackLoss: 0.04060399532318115\n",
      "\n",
      "Episode 495, WhiteLoss: 0.02724035084247589\n",
      "\n",
      "Episode 497, BlackLoss: 0.04045433923602104\n",
      "\n",
      "Episode 497, WhiteLoss: 0.02714361809194088\n",
      "\n",
      "Episode 499, BlackLoss: 0.04030498489737511\n",
      "\n",
      "Episode 499, WhiteLoss: 0.027052365243434906\n",
      "\n",
      "Episode 501, BlackLoss: 0.040155403316020966\n",
      "\n",
      "Episode 501, WhiteLoss: 0.02695808932185173\n",
      "\n",
      "save \n",
      "Episode 503, BlackLoss: 0.04000815376639366\n",
      "\n",
      "Episode 503, WhiteLoss: 0.026868270710110664\n",
      "\n",
      "Episode 505, BlackLoss: 0.03985968977212906\n",
      "\n",
      "Episode 505, WhiteLoss: 0.026774995028972626\n",
      "\n",
      "Episode 508, BlackLoss: 0.039717063307762146\n",
      "\n",
      "Episode 508, WhiteLoss: 0.02668481133878231\n",
      "\n",
      "Episode 510, BlackLoss: 0.03957110643386841\n",
      "\n",
      "Episode 510, WhiteLoss: 0.02659691497683525\n",
      "\n",
      "update Target Model\n",
      "Episode 512, BlackLoss: 0.039427779614925385\n",
      "\n",
      "Episode 512, WhiteLoss: 0.026510566473007202\n",
      "\n",
      "Episode 514, BlackLoss: 0.039286233484745026\n",
      "\n",
      "Episode 514, WhiteLoss: 0.0264267735183239\n",
      "\n",
      "Episode 517, BlackLoss: 0.03914408013224602\n",
      "\n",
      "Episode 517, WhiteLoss: 0.026341291144490242\n",
      "\n",
      "Episode 519, BlackLoss: 0.039008256047964096\n",
      "\n",
      "Episode 519, WhiteLoss: 0.026256944984197617\n",
      "\n",
      "Episode 521, BlackLoss: 0.03887549415230751\n",
      "\n",
      "Episode 521, WhiteLoss: 0.026172613725066185\n",
      "\n",
      "Episode 523, BlackLoss: 0.03874729573726654\n",
      "\n",
      "Episode 523, WhiteLoss: 0.026091575622558594\n",
      "\n",
      "Episode 525, BlackLoss: 0.03861641511321068\n",
      "\n",
      "Episode 525, WhiteLoss: 0.02600627765059471\n",
      "\n",
      "Episode 527, BlackLoss: 0.03848743811249733\n",
      "\n",
      "Episode 527, WhiteLoss: 0.025922315195202827\n",
      "\n",
      "Episode 529, BlackLoss: 0.038354355841875076\n",
      "\n",
      "Episode 529, WhiteLoss: 0.025841346010565758\n",
      "\n",
      "Episode 531, BlackLoss: 0.03822309523820877\n",
      "\n",
      "Episode 531, WhiteLoss: 0.02575984224677086\n",
      "\n",
      "Episode 534, BlackLoss: 0.03809422627091408\n",
      "\n",
      "Episode 534, WhiteLoss: 0.025672640651464462\n",
      "\n",
      "Episode 536, BlackLoss: 0.03796742483973503\n",
      "\n",
      "Episode 536, WhiteLoss: 0.02559029310941696\n",
      "\n",
      "Episode 538, BlackLoss: 0.037848517298698425\n",
      "\n",
      "Episode 538, WhiteLoss: 0.025509392842650414\n",
      "\n",
      "Episode 540, BlackLoss: 0.03772367164492607\n",
      "\n",
      "Episode 540, WhiteLoss: 0.02542736940085888\n",
      "\n",
      "update Target Model\n",
      "Episode 542, BlackLoss: 0.03759519383311272\n",
      "\n",
      "Episode 542, WhiteLoss: 0.025347774848341942\n",
      "\n",
      "Episode 544, BlackLoss: 0.037470314651727676\n",
      "\n",
      "Episode 544, WhiteLoss: 0.02526971511542797\n",
      "\n",
      "Episode 546, BlackLoss: 0.037345897406339645\n",
      "\n",
      "Episode 546, WhiteLoss: 0.0251935962587595\n",
      "\n",
      "Episode 549, BlackLoss: 0.037219274789094925\n",
      "\n",
      "Episode 549, WhiteLoss: 0.02511906810104847\n",
      "\n",
      "Episode 551, BlackLoss: 0.037094615399837494\n",
      "\n",
      "Episode 551, WhiteLoss: 0.025039950385689735\n",
      "\n",
      "Episode 553, BlackLoss: 0.03697866201400757\n",
      "\n",
      "Episode 553, WhiteLoss: 0.024965720251202583\n",
      "\n",
      "Episode 555, BlackLoss: 0.03685586899518967\n",
      "\n",
      "Episode 555, WhiteLoss: 0.024895010516047478\n",
      "\n",
      "Episode 557, BlackLoss: 0.03673548623919487\n",
      "\n",
      "Episode 557, WhiteLoss: 0.02482154779136181\n",
      "\n",
      "Episode 559, BlackLoss: 0.03661809116601944\n",
      "\n",
      "Episode 559, WhiteLoss: 0.024746501818299294\n",
      "\n",
      "Episode 561, BlackLoss: 0.036500778049230576\n",
      "\n",
      "Episode 561, WhiteLoss: 0.02467980980873108\n",
      "\n",
      "Episode 564, BlackLoss: 0.03638172522187233\n",
      "\n",
      "Episode 564, WhiteLoss: 0.024616684764623642\n",
      "\n",
      "Episode 566, BlackLoss: 0.03626209869980812\n",
      "\n",
      "Episode 566, WhiteLoss: 0.024555468931794167\n",
      "\n",
      "Episode 568, BlackLoss: 0.036149684339761734\n",
      "\n",
      "Episode 568, WhiteLoss: 0.024492789059877396\n",
      "\n",
      "Episode 570, BlackLoss: 0.03603464737534523\n",
      "\n",
      "Episode 570, WhiteLoss: 0.024427110329270363\n",
      "\n",
      "update Target Model\n",
      "Episode 572, BlackLoss: 0.03591574355959892\n",
      "\n",
      "Episode 572, WhiteLoss: 0.024363774806261063\n",
      "\n",
      "Episode 574, BlackLoss: 0.035800233483314514\n",
      "\n",
      "Episode 574, WhiteLoss: 0.024293703958392143\n",
      "\n",
      "Episode 576, BlackLoss: 0.03568970039486885\n",
      "\n",
      "Episode 576, WhiteLoss: 0.02423141710460186\n",
      "\n",
      "Episode 578, BlackLoss: 0.035574205219745636\n",
      "\n",
      "Episode 578, WhiteLoss: 0.024167710915207863\n",
      "\n",
      "Episode 581, BlackLoss: 0.035461414605379105\n",
      "\n",
      "Episode 581, WhiteLoss: 0.024104706943035126\n",
      "\n",
      "Episode 583, BlackLoss: 0.035347506403923035\n",
      "\n",
      "Episode 583, WhiteLoss: 0.024046940729022026\n",
      "\n",
      "Episode 585, BlackLoss: 0.03523962199687958\n",
      "\n",
      "Episode 585, WhiteLoss: 0.023981628939509392\n",
      "\n",
      "Episode 587, BlackLoss: 0.035132329910993576\n",
      "\n",
      "Episode 587, WhiteLoss: 0.02392035350203514\n",
      "\n",
      "Episode 589, BlackLoss: 0.035028401762247086\n",
      "\n",
      "Episode 589, WhiteLoss: 0.023857999593019485\n",
      "\n",
      "Episode 591, BlackLoss: 0.03491998463869095\n",
      "\n",
      "Episode 591, WhiteLoss: 0.023795517161488533\n",
      "\n",
      "Episode 593, BlackLoss: 0.0348120853304863\n",
      "\n",
      "Episode 593, WhiteLoss: 0.02373167686164379\n",
      "\n",
      "Episode 596, BlackLoss: 0.03470694646239281\n",
      "\n",
      "Episode 596, WhiteLoss: 0.023671690374612808\n",
      "\n",
      "Episode 598, BlackLoss: 0.03460007160902023\n",
      "\n",
      "Episode 598, WhiteLoss: 0.023611538112163544\n",
      "\n",
      "Episode 600, BlackLoss: 0.03450031951069832\n",
      "\n",
      "Episode 600, WhiteLoss: 0.023551881313323975\n",
      "\n",
      "update Target Model\n",
      "save \n",
      "Episode 602, BlackLoss: 0.03439521789550781\n",
      "\n",
      "Episode 602, WhiteLoss: 0.023497968912124634\n",
      "\n",
      "Episode 604, BlackLoss: 0.034295715391635895\n",
      "\n",
      "Episode 604, WhiteLoss: 0.02344447374343872\n",
      "\n",
      "Episode 606, BlackLoss: 0.034196220338344574\n",
      "\n",
      "Episode 606, WhiteLoss: 0.0233915988355875\n",
      "\n",
      "Episode 608, BlackLoss: 0.034095648676157\n",
      "\n",
      "Episode 608, WhiteLoss: 0.0233350470662117\n",
      "\n",
      "Episode 611, BlackLoss: 0.034000396728515625\n",
      "\n",
      "Episode 611, WhiteLoss: 0.023272627964615822\n",
      "\n",
      "Episode 613, BlackLoss: 0.03390078619122505\n",
      "\n",
      "Episode 613, WhiteLoss: 0.02322171814739704\n",
      "\n",
      "Episode 615, BlackLoss: 0.03380393236875534\n",
      "\n",
      "Episode 615, WhiteLoss: 0.023165717720985413\n",
      "\n",
      "Episode 617, BlackLoss: 0.033713988959789276\n",
      "\n",
      "Episode 617, WhiteLoss: 0.023111451417207718\n",
      "\n",
      "Episode 619, BlackLoss: 0.03361799940466881\n",
      "\n",
      "Episode 619, WhiteLoss: 0.023060211911797523\n",
      "\n",
      "Episode 621, BlackLoss: 0.03352627530694008\n",
      "\n",
      "Episode 621, WhiteLoss: 0.023011427372694016\n",
      "\n",
      "Episode 623, BlackLoss: 0.03343329578638077\n",
      "\n",
      "Episode 623, WhiteLoss: 0.022959426045417786\n",
      "\n",
      "Episode 625, BlackLoss: 0.033351246267557144\n",
      "\n",
      "Episode 625, WhiteLoss: 0.02290571853518486\n",
      "\n",
      "Episode 628, BlackLoss: 0.03327269107103348\n",
      "\n",
      "Episode 628, WhiteLoss: 0.022865112870931625\n",
      "\n",
      "Episode 630, BlackLoss: 0.033184878528118134\n",
      "\n",
      "Episode 630, WhiteLoss: 0.022822564467787743\n",
      "\n",
      "update Target Model\n",
      "Episode 632, BlackLoss: 0.03310240060091019\n",
      "\n",
      "Episode 632, WhiteLoss: 0.022795522585511208\n",
      "\n",
      "Episode 634, BlackLoss: 0.03301430866122246\n",
      "\n",
      "Episode 634, WhiteLoss: 0.022770313546061516\n",
      "\n",
      "Episode 636, BlackLoss: 0.03293044865131378\n",
      "\n",
      "Episode 636, WhiteLoss: 0.022739015519618988\n",
      "\n",
      "Episode 639, BlackLoss: 0.032849982380867004\n",
      "\n",
      "Episode 639, WhiteLoss: 0.02272658236324787\n",
      "\n",
      "Episode 641, BlackLoss: 0.03276513144373894\n",
      "\n",
      "Episode 641, WhiteLoss: 0.022704027593135834\n",
      "\n",
      "Episode 643, BlackLoss: 0.032686203718185425\n",
      "\n",
      "Episode 643, WhiteLoss: 0.022700704634189606\n",
      "\n",
      "Episode 645, BlackLoss: 0.032608114182949066\n",
      "\n",
      "Episode 645, WhiteLoss: 0.02270016446709633\n",
      "\n",
      "Episode 648, BlackLoss: 0.03252522274851799\n",
      "\n",
      "Episode 648, WhiteLoss: 0.02269470877945423\n",
      "\n",
      "Episode 650, BlackLoss: 0.03244808688759804\n",
      "\n",
      "Episode 650, WhiteLoss: 0.022697031497955322\n",
      "\n",
      "Episode 652, BlackLoss: 0.0323745533823967\n",
      "\n",
      "Episode 652, WhiteLoss: 0.022698475047945976\n",
      "\n",
      "Episode 654, BlackLoss: 0.032295383512973785\n",
      "\n",
      "Episode 654, WhiteLoss: 0.022696292027831078\n",
      "\n",
      "Episode 657, BlackLoss: 0.032219648361206055\n",
      "\n",
      "Episode 657, WhiteLoss: 0.022711344063282013\n",
      "\n",
      "Episode 659, BlackLoss: 0.0321463868021965\n",
      "\n",
      "Episode 659, WhiteLoss: 0.022712701931595802\n",
      "\n",
      "Episode 661, BlackLoss: 0.03206693008542061\n",
      "\n",
      "Episode 661, WhiteLoss: 0.022726088762283325\n",
      "\n",
      "update Target Model\n",
      "Episode 663, BlackLoss: 0.0319925956428051\n",
      "\n",
      "Episode 663, WhiteLoss: 0.022743327543139458\n",
      "\n",
      "Episode 665, BlackLoss: 0.03191845118999481\n",
      "\n",
      "Episode 665, WhiteLoss: 0.022762572392821312\n",
      "\n",
      "Episode 667, BlackLoss: 0.03184528276324272\n",
      "\n",
      "Episode 667, WhiteLoss: 0.022773010656237602\n",
      "\n",
      "Episode 669, BlackLoss: 0.03176550567150116\n",
      "\n",
      "Episode 669, WhiteLoss: 0.022809389978647232\n",
      "\n",
      "Episode 672, BlackLoss: 0.03169013187289238\n",
      "\n",
      "Episode 672, WhiteLoss: 0.022850358858704567\n",
      "\n",
      "Episode 674, BlackLoss: 0.03162188455462456\n",
      "\n",
      "Episode 674, WhiteLoss: 0.022887077182531357\n",
      "\n",
      "Episode 676, BlackLoss: 0.031548045575618744\n",
      "\n",
      "Episode 676, WhiteLoss: 0.022934017702937126\n",
      "\n",
      "Episode 678, BlackLoss: 0.03147812932729721\n",
      "\n",
      "Episode 678, WhiteLoss: 0.02294609509408474\n",
      "\n",
      "Episode 680, BlackLoss: 0.03140908479690552\n",
      "\n",
      "Episode 680, WhiteLoss: 0.022966496646404266\n",
      "\n",
      "Episode 682, BlackLoss: 0.031350549310445786\n",
      "\n",
      "Episode 682, WhiteLoss: 0.022976987063884735\n",
      "\n",
      "Episode 684, BlackLoss: 0.03129296377301216\n",
      "\n",
      "Episode 684, WhiteLoss: 0.023011554032564163\n",
      "\n",
      "Episode 687, BlackLoss: 0.03123321570456028\n",
      "\n",
      "Episode 687, WhiteLoss: 0.023028982803225517\n",
      "\n",
      "Episode 689, BlackLoss: 0.03117671050131321\n",
      "\n",
      "Episode 689, WhiteLoss: 0.023057077080011368\n",
      "\n",
      "Episode 691, BlackLoss: 0.031117837876081467\n",
      "\n",
      "Episode 691, WhiteLoss: 0.02308639883995056\n",
      "\n",
      "update Target Model\n",
      "Episode 693, BlackLoss: 0.031060947105288506\n",
      "\n",
      "Episode 693, WhiteLoss: 0.023122617974877357\n",
      "\n",
      "Episode 695, BlackLoss: 0.03100188821554184\n",
      "\n",
      "Episode 695, WhiteLoss: 0.023144714534282684\n",
      "\n",
      "Episode 697, BlackLoss: 0.030951377004384995\n",
      "\n",
      "Episode 697, WhiteLoss: 0.02318946085870266\n",
      "\n",
      "Episode 699, BlackLoss: 0.030897824093699455\n",
      "\n",
      "Episode 699, WhiteLoss: 0.023231884464621544\n",
      "\n",
      "Episode 701, BlackLoss: 0.030837642028927803\n",
      "\n",
      "Episode 701, WhiteLoss: 0.023282533511519432\n",
      "\n",
      "save \n",
      "Episode 704, BlackLoss: 0.030793407931923866\n",
      "\n",
      "Episode 704, WhiteLoss: 0.023324763402342796\n",
      "\n",
      "Episode 706, BlackLoss: 0.030739668756723404\n",
      "\n",
      "Episode 706, WhiteLoss: 0.0233873650431633\n",
      "\n",
      "Episode 708, BlackLoss: 0.03069285675883293\n",
      "\n",
      "Episode 708, WhiteLoss: 0.02341940812766552\n",
      "\n",
      "Episode 710, BlackLoss: 0.030632350593805313\n",
      "\n",
      "Episode 710, WhiteLoss: 0.02346394956111908\n",
      "\n",
      "Episode 712, BlackLoss: 0.0305742509663105\n",
      "\n",
      "Episode 712, WhiteLoss: 0.02350020967423916\n",
      "\n",
      "Episode 714, BlackLoss: 0.030515674501657486\n",
      "\n",
      "Episode 714, WhiteLoss: 0.023533260449767113\n",
      "\n",
      "Episode 716, BlackLoss: 0.030455823987722397\n",
      "\n",
      "Episode 716, WhiteLoss: 0.023590989410877228\n",
      "\n",
      "Episode 719, BlackLoss: 0.030405746772885323\n",
      "\n",
      "Episode 719, WhiteLoss: 0.02366810478270054\n",
      "\n",
      "Episode 721, BlackLoss: 0.030348286032676697\n",
      "\n",
      "Episode 721, WhiteLoss: 0.02372787706553936\n",
      "\n",
      "update Target Model\n",
      "Episode 723, BlackLoss: 0.03028571978211403\n",
      "\n",
      "Episode 723, WhiteLoss: 0.023801758885383606\n",
      "\n",
      "Episode 725, BlackLoss: 0.030220387503504753\n",
      "\n",
      "Episode 725, WhiteLoss: 0.023865556344389915\n",
      "\n",
      "Episode 727, BlackLoss: 0.030160322785377502\n",
      "\n",
      "Episode 727, WhiteLoss: 0.023975661024451256\n",
      "\n",
      "Episode 729, BlackLoss: 0.03010265901684761\n",
      "\n",
      "Episode 729, WhiteLoss: 0.024063169956207275\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m turn \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mturn\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     37\u001b[0m oldobs \u001b[38;5;241m=\u001b[39m obs\n\u001b[1;32m---> 38\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mGetPolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43mturn\u001b[49m\u001b[43m,\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m obs, reward, done, _, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m, in \u001b[0;36mGetPolicy\u001b[1;34m(bdone, wdone, turn, env, obs, actions)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(bdone):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBlackdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBehaviorPolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mturn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(wdone):\n",
      "File \u001b[1;32mc:\\Users\\zx288\\Desktop\\Othello\\DeepQResNet.py:107\u001b[0m, in \u001b[0;36mDQN.BehaviorPolicy\u001b[1;34m(self, env, state, turn, valid_action)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mBehaviorPolicy\u001b[39m(\u001b[38;5;28mself\u001b[39m, env,state,turn,valid_action):\n\u001b[1;32m--> 107\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mturn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][valid_action]\n\u001b[0;32m    109\u001b[0m     count \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(valid_action)):\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:442\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m, x, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    440\u001b[0m ):\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;66;03m# Create an iterator that yields batches of input data.\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     epoch_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:625\u001b[0m, in \u001b[0;36mTFEpochIterator.__init__\u001b[1;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy \u001b[38;5;241m=\u001b[39m distribute_strategy\n\u001b[1;32m--> 625\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedDataset):\n\u001b[0;32m    627\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy\u001b[38;5;241m.\u001b[39mexperimental_distribute_dataset(\n\u001b[0;32m    628\u001b[0m         dataset\n\u001b[0;32m    629\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:634\u001b[0m, in \u001b[0;36mTFEpochIterator._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_iterator\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:236\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    234\u001b[0m     indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mmap(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle)\n\u001b[1;32m--> 236\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n\u001b[0;32m    239\u001b[0m options\u001b[38;5;241m.\u001b[39mexperimental_distribute\u001b[38;5;241m.\u001b[39mauto_shard_policy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    240\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAutoShardPolicy\u001b[38;5;241m.\u001b[39mDATA\n\u001b[0;32m    241\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:215\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset.<locals>.slice_inputs\u001b[1;34m(indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mtraverse(grab_one, data)\n\u001b[1;32m--> 215\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrab_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Default optimizations are disabled to avoid the overhead of\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# (unnecessary) input pipeline graph serialization & deserialization\u001b[39;00m\n\u001b[0;32m    221\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2299\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2296\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2297\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2298\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2300\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m     37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[0;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1251\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1250\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1221\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1219\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1220\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m   1225\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1226\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    694\u001b[0m )\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:340\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    331\u001b[0m output_type \u001b[38;5;241m=\u001b[39m trace_type\u001b[38;5;241m.\u001b[39mfrom_value(\n\u001b[0;32m    332\u001b[0m     traced_func_graph\u001b[38;5;241m.\u001b[39mstructured_outputs, type_context\n\u001b[0;32m    333\u001b[0m )\n\u001b[0;32m    334\u001b[0m traced_func_type \u001b[38;5;241m=\u001b[39m function_type_lib\u001b[38;5;241m.\u001b[39mFunctionType(\n\u001b[0;32m    335\u001b[0m     function_type\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    336\u001b[0m     traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\u001b[38;5;241m.\u001b[39mcapture_types,\n\u001b[0;32m    337\u001b[0m     return_annotation\u001b[38;5;241m=\u001b[39moutput_type,\n\u001b[0;32m    338\u001b[0m )\n\u001b[1;32m--> 340\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43mconcrete_function_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcreteFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_func_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraced_func_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraced_func_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;49;00m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# scope. This is not the default behavior since it gets used in some\u001b[39;49;00m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;49;00m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ConcreteFunction.\u001b[39;49;00m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshared_func_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m _set_arg_keywords(concrete_function)\n\u001b[0;32m    351\u001b[0m transform\u001b[38;5;241m.\u001b[39mcall_concrete_function_callbacks(concrete_function)\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1075\u001b[0m, in \u001b[0;36mConcreteFunction.from_func_graph\u001b[1;34m(cls, graph, function_type, attrs, shared_func_graph)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_func_graph\u001b[39m(\u001b[38;5;28mcls\u001b[39m, graph, function_type, attrs, shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 1075\u001b[0m   atomic_fn \u001b[38;5;241m=\u001b[39m \u001b[43matomic_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_func_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_inference_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_type\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1078\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ConcreteFunction(atomic_fn, shared_func_graph\u001b[38;5;241m=\u001b[39mshared_func_graph)\n",
      "File \u001b[1;32mc:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:537\u001b[0m, in \u001b[0;36mfrom_func_graph\u001b[1;34m(name, graph, attrs, function_type, overwrite)\u001b[0m\n\u001b[0;32m    535\u001b[0m   output_names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39m_c_graph\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mas\u001b[39;00m c_graph:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m   fn \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_GraphToFunction_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m      \u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moperations\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    542\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_tf_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    543\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_tf_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    544\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol_outputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    546\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# control_output_names\u001b[39;49;00m\n\u001b[0;32m    547\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m attrs \u001b[38;5;241m=\u001b[39m attributes_lib\u001b[38;5;241m.\u001b[39mparse_func_attrs(attrs \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr_name, attr_value \u001b[38;5;129;01min\u001b[39;00m attrs\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.metadata['autoplay'] = True\n",
    "env.metadata['render_fps'] = 150000\n",
    "obs, reward, bdone, _, info = env.reset()\n",
    "state_shape = (8, 8, 1)  # Adding the channel dimension\n",
    "Blackdqn = DQN(state_shape,env.action_space.n)\n",
    "Whitedqn = DQN(state_shape,env.action_space.n)\n",
    "\n",
    "version = -1\n",
    "# Blackdqn.load( f\"model/UCT/Black/Model_{version}.weights.h5\")\n",
    "# Whitedqn.load(f\"model/UCT/White/Model_{version}.weights.h5\")\n",
    "BlackmodelCount = version +1\n",
    "WhitemodelCount = version +1\n",
    "def GetPolicy(bdone,wdone,turn,env,obs,actions):\n",
    "    if(not actions):\n",
    "        return None\n",
    "    if(turn==1):\n",
    "        if(bdone):\n",
    "            return None\n",
    "        return Blackdqn.BehaviorPolicy(env,obs,turn,actions)\n",
    "    else:\n",
    "        if(wdone):\n",
    "            return None\n",
    "        return Whitedqn.BehaviorPolicy(env,obs,turn,actions)\n",
    "def InsertBuffer(turn,oldobs, action, reward,obs,done,actions):\n",
    "    Blackdqn.InsertBuffer(oldobs, action, reward,obs,done,actions,turn)\n",
    "    Whitedqn.InsertBuffer(oldobs, action, reward,obs,done,actions,turn)\n",
    "for episode in range(1,10000):\n",
    "    bdone = False\n",
    "    wdone = False\n",
    "    obs, reward, done, _, info = env.reset()\n",
    "    steps = 0\n",
    "    while (not bdone) or (not wdone):\n",
    "        actions = info['action']\n",
    "        turn = info['turn']\n",
    "        oldobs = obs\n",
    "        action = GetPolicy(bdone,wdone,turn,env,obs,actions)\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        if done:\n",
    "            if info['turn'] ==2:\n",
    "                wdone = True\n",
    "            else:\n",
    "                bdone = True\n",
    "        if(action is not None):\n",
    "            InsertBuffer(turn,oldobs, action, reward,obs,done,actions)\n",
    "        steps += 1\n",
    "    blakloss = Blackdqn.train()\n",
    "    whiteloss = Whitedqn.train()\n",
    "    if blakloss is not None:\n",
    "        print(f\"Episode {episode + 1}, BlackLoss: {blakloss}\\n\")\n",
    "        Blackdqn.update_target_model()\n",
    "    if whiteloss is not None:\n",
    "        print(f\"Episode {episode + 1}, WhiteLoss: {whiteloss}\\n\")\n",
    "        Whitedqn.update_target_model()\n",
    "    if(episode % 30 == 0):\n",
    "        print(\"update Target Model\")\n",
    "        Blackdqn.update_target_model()\n",
    "        Whitedqn.update_target_model()\n",
    "    if(episode % 100 == 0):\n",
    "        print('save ')\n",
    "        Whitedqn.save(f\"model/BlackModel_{WhitemodelCount}.weights.h5\")\n",
    "        Blackdqn.save(f\"model/WhiteModel_{BlackmodelCount}.weights.h5\")\n",
    "        BlackmodelCount+=1\n",
    "        WhitemodelCount+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트\n",
    "\n",
    "**방법**\n",
    "1. load를 통해 원하는 모델 선택\n",
    "2. BlackPlay를 지정해 돌 색 선택\n",
    "   \n",
    "**notice**\n",
    "\n",
    "더 이상 둘 수 있는 수가 없다면 자동으로 턴이 넘어 갑니다.\n",
    "게임이 완료되었다는 문구 출력을 만들지 않았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:193: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` should be `(obs, info)` by default, , where `obs` is a observation and `info` is a dictionary containing additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:323: UserWarning: \u001b[33mWARN: Expects the render_modes to be a sequence (i.e. list, tuple), actual type: <class 'str'>\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "BlackPlay = False # 사람이 무슨 색 돌로 시작할 건지\n",
    "\n",
    "env.metadata['render_fps'] = 60\n",
    "env.metadata['autoplay'] = not BlackPlay\n",
    "obs, reward, done, _, info = env.reset()\n",
    "dqn = DQN(state_shape,env.action_space.n)\n",
    "dqn.load('model/UCT/Black/BlackModel_6.weights.h5') # 테스트 모델 선택\n",
    "bdone = False\n",
    "wdone = False\n",
    "def GetPolicy(bdone,wdone,turn,env,obs,actions):\n",
    "    if(not actions):\n",
    "        return None\n",
    "    if(turn==1):\n",
    "        if(bdone):\n",
    "            return None\n",
    "    else:\n",
    "        if(wdone):\n",
    "            return None\n",
    "    if(not env.metadata['autoplay']):\n",
    "        return None\n",
    "    return dqn.EstimatePolicy(obs,turn,actions)\n",
    "\n",
    "while (not bdone) or (not wdone):\n",
    "    actions = info['action']\n",
    "    turn = info['turn']\n",
    "    oldobs = obs\n",
    "    time.sleep(0.5)\n",
    "    action = GetPolicy(bdone,wdone,turn,env,obs,actions)\n",
    "    obs, reward, done, _, info = env.step(action)\n",
    "    env.metadata['autoplay'] = not env.metadata['autoplay']\n",
    "    env.render()\n",
    "    if done:\n",
    "        if info['turn'] ==2:\n",
    "            wdone = True\n",
    "        else:\n",
    "            bdone = True\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
