{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_games\n",
    "import random\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from DeepQResNet import DQN\n",
    "\n",
    "env = gym.make('Othello-v0',render_mode='human')\n",
    "state_shape = (8, 8, 1)  # Adding the channel dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reward\n",
    "\n",
    "기본 : 자신의 색돌 이득 - 상대 색돌 이득\n",
    "게임 종료 보상 : +100/ -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy 정책 학습 진행\n",
    "\n",
    "<details>\n",
    "  <summary>Loss</summary>\n",
    "Episode 6, BlackLoss: 2.5871880054473877\n",
    "\n",
    "Episode 10, BlackLoss: 3.463204860687256\n",
    "\n",
    "Episode 14, BlackLoss: 5.1391706466674805\n",
    "\n",
    "Episode 18, BlackLoss: 4.149457931518555\n",
    "\n",
    "Episode 27, BlackLoss: 3.679093599319458\n",
    "\n",
    "Episode 31, BlackLoss: 3.9321818351745605\n",
    "\n",
    "Episode 35, BlackLoss: 3.508091449737549\n",
    "\n",
    "Episode 40, BlackLoss: 3.5931766033172607\n",
    "\n",
    "Episode 44, BlackLoss: 3.542747974395752\n",
    "\n",
    "Episode 48, BlackLoss: 3.7177977561950684\n",
    "\n",
    "Episode 52, BlackLoss: 3.8610305786132812\n",
    "\n",
    "Episode 57, BlackLoss: 3.606940746307373\n",
    "\n",
    "Episode 61, BlackLoss: 3.57145619392395\n",
    "\n",
    "Episode 65, BlackLoss: 3.3747918605804443\n",
    "\n",
    "Episode 69, BlackLoss: 3.3560681343078613\n",
    "\n",
    "Episode 74, BlackLoss: 3.3358588218688965\n",
    "\n",
    "Episode 78, BlackLoss: 3.1866283416748047\n",
    "\n",
    "Episode 82, BlackLoss: 3.1829605102539062\n",
    "\n",
    "Episode 86, BlackLoss: 3.173980712890625\n",
    "\n",
    "Episode 91, BlackLoss: 3.1648879051208496\n",
    "\n",
    "Episode 95, BlackLoss: 3.151181221008301\n",
    "\n",
    "Episode 99, BlackLoss: 3.040142774581909\n",
    "\n",
    "save \n",
    "Episode 103, BlackLoss: 3.1868131160736084\n",
    "\n",
    "Episode 108, BlackLoss: 3.1766295433044434\n",
    "\n",
    "Episode 112, BlackLoss: 3.0779967308044434\n",
    "\n",
    "Episode 116, BlackLoss: 3.030778408050537\n",
    "\n",
    "Episode 121, BlackLoss: 2.985933303833008\n",
    "\n",
    "Episode 125, BlackLoss: 3.071744680404663\n",
    "\n",
    "Episode 129, BlackLoss: 3.0710091590881348\n",
    "\n",
    "Episode 133, BlackLoss: 3.105374813079834\n",
    "\n",
    "Episode 138, BlackLoss: 3.062744379043579\n",
    "\n",
    "Episode 142, BlackLoss: 3.2064716815948486\n",
    "\n",
    "Episode 146, BlackLoss: 3.376955032348633\n",
    "\n",
    "Episode 150, BlackLoss: 3.4334678649902344\n",
    "\n",
    "Episode 154, BlackLoss: 3.460362434387207\n",
    "\n",
    "Episode 159, BlackLoss: 3.481163740158081\n",
    "\n",
    "Episode 163, BlackLoss: 3.403533935546875\n",
    "\n",
    "Episode 167, BlackLoss: 3.33117413520813\n",
    "\n",
    "Episode 171, BlackLoss: 3.3817806243896484\n",
    "\n",
    "Episode 176, BlackLoss: 3.370361328125\n",
    "\n",
    "Episode 180, BlackLoss: 3.4187614917755127\n",
    "\n",
    "Episode 184, BlackLoss: 3.3530402183532715\n",
    "\n",
    "Episode 189, BlackLoss: 3.3176398277282715\n",
    "\n",
    "Episode 193, BlackLoss: 3.2543601989746094\n",
    "\n",
    "Episode 197, BlackLoss: 3.195603847503662\n",
    "\n",
    "Episode 201, BlackLoss: 3.191741704940796\n",
    "\n",
    "save \n",
    "Episode 206, BlackLoss: 3.1867544651031494\n",
    "\n",
    "Episode 210, BlackLoss: 3.132033586502075\n",
    "\n",
    "Episode 214, BlackLoss: 3.082047700881958\n",
    "\n",
    "Episode 219, BlackLoss: 3.0823540687561035\n",
    "\n",
    "Episode 223, BlackLoss: 3.175480365753174\n",
    "\n",
    "Episode 227, BlackLoss: 3.126458168029785\n",
    "\n",
    "Episode 231, BlackLoss: 3.1250667572021484\n",
    "\n",
    "Episode 236, BlackLoss: 3.0768470764160156\n",
    "\n",
    "Episode 240, BlackLoss: 3.032946825027466\n",
    "\n",
    "Episode 244, BlackLoss: 2.990708827972412\n",
    "\n",
    "Episode 249, BlackLoss: 3.032198190689087\n",
    "\n",
    "Episode 253, BlackLoss: 2.989483118057251\n",
    "\n",
    "Episode 257, BlackLoss: 3.030371904373169\n",
    "\n",
    "Episode 261, BlackLoss: 2.9905757904052734\n",
    "\n",
    "Episode 266, BlackLoss: 2.951904296875\n",
    "\n",
    "Episode 270, BlackLoss: 2.9522154331207275\n",
    "\n",
    "Episode 274, BlackLoss: 2.9518439769744873\n",
    "\n",
    "Episode 278, BlackLoss: 2.9143218994140625\n",
    "\n",
    "Episode 283, BlackLoss: 2.9167160987854004\n",
    "\n",
    "Episode 287, BlackLoss: 2.917654037475586\n",
    "\n",
    "Episode 291, BlackLoss: 2.953550100326538\n",
    "\n",
    "Episode 295, BlackLoss: 2.953828811645508\n",
    "\n",
    "Episode 300, BlackLoss: 2.9529740810394287\n",
    "\n",
    "save \n",
    "Episode 304, BlackLoss: 2.9187164306640625\n",
    "\n",
    "Episode 309, BlackLoss: 2.953761100769043\n",
    "\n",
    "Episode 313, BlackLoss: 2.988124370574951\n",
    "\n",
    "Episode 318, BlackLoss: 3.0036702156066895\n",
    "\n",
    "Episode 322, BlackLoss: 3.0039021968841553\n",
    "\n",
    "Episode 326, BlackLoss: 2.9699480533599854\n",
    "\n",
    "Episode 331, BlackLoss: 2.938927173614502\n",
    "\n",
    "Episode 335, BlackLoss: 2.9088685512542725\n",
    "\n",
    "Episode 339, BlackLoss: 2.9411582946777344\n",
    "\n",
    "Episode 343, BlackLoss: 2.9424285888671875\n",
    "\n",
    "Episode 348, BlackLoss: 2.9726979732513428\n",
    "\n",
    "Episode 352, BlackLoss: 3.0024232864379883\n",
    "\n",
    "Episode 356, BlackLoss: 3.002262830734253\n",
    "\n",
    "Episode 360, BlackLoss: 3.0442698001861572\n",
    "\n",
    "Episode 364, BlackLoss: 3.056975841522217\n",
    "\n",
    "Episode 369, BlackLoss: 3.0852277278900146\n",
    "\n",
    "Episode 373, BlackLoss: 3.0844855308532715\n",
    "\n",
    "Episode 377, BlackLoss: 3.1101694107055664\n",
    "\n",
    "Episode 381, BlackLoss: 3.0820846557617188\n",
    "\n",
    "Episode 386, BlackLoss: 3.0814805030822754\n",
    "\n",
    "Episode 390, BlackLoss: 3.054316520690918\n",
    "\n",
    "Episode 394, BlackLoss: 3.0537467002868652\n",
    "\n",
    "Episode 398, BlackLoss: 3.07959246635437\n",
    "\n",
    "save \n",
    "Episode 403, BlackLoss: 3.0806894302368164\n",
    "\n",
    "Episode 407, BlackLoss: 3.054084539413452\n",
    "\n",
    "Episode 411, BlackLoss: 3.1044270992279053\n",
    "\n",
    "Episode 415, BlackLoss: 3.1042098999023438\n",
    "\n",
    "Episode 419, BlackLoss: 3.1041157245635986\n",
    "\n",
    "Episode 424, BlackLoss: 3.0908873081207275\n",
    "\n",
    "Episode 428, BlackLoss: 3.102454423904419\n",
    "\n",
    "Episode 433, BlackLoss: 3.077482223510742\n",
    "\n",
    "Episode 437, BlackLoss: 3.0524628162384033\n",
    "\n",
    "Episode 441, BlackLoss: 3.0520520210266113\n",
    "\n",
    "Episode 445, BlackLoss: 3.051460027694702\n",
    "\n",
    "Episode 450, BlackLoss: 3.085820198059082\n",
    "\n",
    "Episode 454, BlackLoss: 3.0860085487365723\n",
    "\n",
    "Episode 458, BlackLoss: 3.0620391368865967\n",
    "\n",
    "Episode 462, BlackLoss: 3.0953369140625\n",
    "\n",
    "Episode 467, BlackLoss: 3.1174612045288086\n",
    "\n",
    "Episode 471, BlackLoss: 3.139265298843384\n",
    "\n",
    "Episode 475, BlackLoss: 3.1166815757751465\n",
    "\n",
    "Episode 479, BlackLoss: 3.0945606231689453\n",
    "\n",
    "Episode 484, BlackLoss: 3.0937538146972656\n",
    "\n",
    "Episode 488, BlackLoss: 3.0719974040985107\n",
    "\n",
    "Episode 492, BlackLoss: 3.0498476028442383\n",
    "\n",
    "Episode 496, BlackLoss: 3.0498576164245605\n",
    "\n",
    "Episode 501, BlackLoss: 3.0278518199920654\n",
    "\n",
    "save \n",
    "Episode 505, BlackLoss: 3.006810426712036\n",
    "\n",
    "Episode 509, BlackLoss: 2.9861109256744385\n",
    "\n",
    "Episode 514, BlackLoss: 2.9870431423187256\n",
    "\n",
    "Episode 518, BlackLoss: 3.0076773166656494\n",
    "\n",
    "Episode 522, BlackLoss: 2.987401008605957\n",
    "\n",
    "Episode 526, BlackLoss: 3.0076205730438232\n",
    "\n",
    "Episode 531, BlackLoss: 3.027428150177002\n",
    "\n",
    "Episode 535, BlackLoss: 3.0076022148132324\n",
    "\n",
    "Episode 539, BlackLoss: 2.988492965698242\n",
    "\n",
    "Episode 543, BlackLoss: 2.9890167713165283\n",
    "\n",
    "Episode 548, BlackLoss: 2.98954176902771\n",
    "\n",
    "Episode 552, BlackLoss: 3.0088918209075928\n",
    "\n",
    "Episode 556, BlackLoss: 3.009981393814087\n",
    "\n",
    "Episode 560, BlackLoss: 3.0098211765289307\n",
    "\n",
    "Episode 565, BlackLoss: 3.0094993114471436\n",
    "\n",
    "Episode 569, BlackLoss: 3.036020278930664\n",
    "\n",
    "Episode 573, BlackLoss: 3.05360746383667\n",
    "\n",
    "Episode 578, BlackLoss: 3.035468578338623\n",
    "\n",
    "Episode 582, BlackLoss: 3.0173051357269287\n",
    "\n",
    "Episode 586, BlackLoss: 2.9994912147521973\n",
    "\n",
    "Episode 590, BlackLoss: 3.0351366996765137\n",
    "\n",
    "Episode 595, BlackLoss: 3.0353732109069824\n",
    "\n",
    "Episode 599, BlackLoss: 3.0352542400360107\n",
    "\n",
    "save \n",
    "Episode 603, BlackLoss: 3.0348329544067383\n",
    "\n",
    "Episode 607, BlackLoss: 3.051917314529419\n",
    "\n",
    "Episode 612, BlackLoss: 3.0512874126434326\n",
    "\n",
    "Episode 616, BlackLoss: 3.0511717796325684\n",
    "\n",
    "Episode 620, BlackLoss: 3.0506482124328613\n",
    "\n",
    "Episode 624, BlackLoss: 3.050370693206787\n",
    "\n",
    "Episode 629, BlackLoss: 3.0579347610473633\n",
    "\n",
    "Episode 633, BlackLoss: 3.057583808898926\n",
    "\n",
    "Episode 637, BlackLoss: 3.089665651321411\n",
    "\n",
    "Episode 641, BlackLoss: 3.073533773422241\n",
    "\n",
    "Episode 646, BlackLoss: 3.0567641258239746\n",
    "\n",
    "Episode 650, BlackLoss: 3.040072441101074\n",
    "\n",
    "Episode 654, BlackLoss: 3.0715909004211426\n",
    "\n",
    "Episode 658, BlackLoss: 3.0703823566436768\n",
    "\n",
    "Episode 663, BlackLoss: 3.0546658039093018\n",
    "\n",
    "Episode 667, BlackLoss: 3.03902268409729\n",
    "\n",
    "Episode 671, BlackLoss: 3.0237228870391846\n",
    "\n",
    "Episode 676, BlackLoss: 3.0079925060272217\n",
    "\n",
    "Episode 680, BlackLoss: 2.992561101913452\n",
    "\n",
    "Episode 684, BlackLoss: 2.992285966873169\n",
    "\n",
    "Episode 688, BlackLoss: 2.992417097091675\n",
    "\n",
    "Episode 692, BlackLoss: 2.9848153591156006\n",
    "\n",
    "Episode 697, BlackLoss: 2.9920804500579834\n",
    "\n",
    "Episode 701, BlackLoss: 3.0068881511688232\n",
    "\n",
    "save \n",
    "Episode 705, BlackLoss: 3.0141355991363525\n",
    "\n",
    "Episode 710, BlackLoss: 3.0141959190368652\n",
    "\n",
    "Episode 714, BlackLoss: 2.9988906383514404\n",
    "\n",
    "Episode 718, BlackLoss: 2.9845659732818604\n",
    "\n",
    "Episode 722, BlackLoss: 2.9782238006591797\n",
    "\n",
    "Episode 727, BlackLoss: 2.9711766242980957\n",
    "\n",
    "Episode 732, BlackLoss: 2.9850480556488037\n",
    "\n",
    "Episode 736, BlackLoss: 2.9708750247955322\n",
    "\n",
    "Episode 740, BlackLoss: 2.9570424556732178\n",
    "\n",
    "Episode 745, BlackLoss: 2.9578917026519775\n",
    "\n",
    "Episode 749, BlackLoss: 2.944425582885742\n",
    "\n",
    "Episode 753, BlackLoss: 2.944127082824707\n",
    "\n",
    "Episode 758, BlackLoss: 2.9441816806793213\n",
    "\n",
    "Episode 762, BlackLoss: 2.943875312805176\n",
    "\n",
    "Episode 766, BlackLoss: 2.9577057361602783\n",
    "\n",
    "Episode 771, BlackLoss: 2.9510297775268555\n",
    "\n",
    "Episode 775, BlackLoss: 2.9507105350494385\n",
    "\n",
    "Episode 779, BlackLoss: 2.937410831451416\n",
    "\n",
    "Episode 783, BlackLoss: 2.9244141578674316\n",
    "\n",
    "Episode 788, BlackLoss: 2.925107955932617\n",
    "\n",
    "Episode 792, BlackLoss: 2.9254150390625\n",
    "\n",
    "Episode 796, BlackLoss: 2.9128079414367676\n",
    "\n",
    "Episode 800, BlackLoss: 2.9005346298217773\n",
    "\n",
    "save \n",
    "Episode 805, BlackLoss: 2.8875348567962646\n",
    "\n",
    "Episode 809, BlackLoss: 2.8885080814361572\n",
    "\n",
    "Episode 813, BlackLoss: 2.901172161102295\n",
    "\n",
    "Episode 818, BlackLoss: 2.9011921882629395\n",
    "\n",
    "Episode 822, BlackLoss: 2.88885760307312\n",
    "\n",
    "Episode 826, BlackLoss: 2.876453399658203\n",
    "\n",
    "Episode 831, BlackLoss: 2.8648879528045654\n",
    "\n",
    "Episode 835, BlackLoss: 2.8781144618988037\n",
    "\n",
    "Episode 839, BlackLoss: 2.866349458694458\n",
    "\n",
    "Episode 843, BlackLoss: 2.854135036468506\n",
    "\n",
    "Episode 848, BlackLoss: 2.854923963546753\n",
    "\n",
    "Episode 852, BlackLoss: 2.8554656505584717\n",
    "\n",
    "Episode 856, BlackLoss: 2.856794834136963\n",
    "\n",
    "Episode 861, BlackLoss: 2.857609748840332\n",
    "\n",
    "Episode 865, BlackLoss: 2.846059560775757\n",
    "\n",
    "Episode 869, BlackLoss: 2.8467981815338135\n",
    "\n",
    "Episode 873, BlackLoss: 2.852933645248413\n",
    "\n",
    "Episode 878, BlackLoss: 2.854013204574585\n",
    "\n",
    "Episode 882, BlackLoss: 2.855092763900757\n",
    "\n",
    "Episode 886, BlackLoss: 2.843994617462158\n",
    "\n",
    "Episode 890, BlackLoss: 2.844486713409424\n",
    "\n",
    "Episode 895, BlackLoss: 2.8568437099456787\n",
    "\n",
    "Episode 899, BlackLoss: 2.857313871383667\n",
    "\n",
    "save \n",
    "Episode 903, BlackLoss: 2.846393585205078\n",
    "\n",
    "Episode 907, BlackLoss: 2.847029685974121\n",
    "\n",
    "Episode 912, BlackLoss: 2.847660779953003\n",
    "\n",
    "Episode 916, BlackLoss: 2.848156213760376\n",
    "\n",
    "Episode 920, BlackLoss: 2.837475538253784\n",
    "\n",
    "Episode 924, BlackLoss: 2.8268706798553467\n",
    "\n",
    "Episode 929, BlackLoss: 2.8280680179595947\n",
    "\n",
    "Episode 933, BlackLoss: 2.8173558712005615\n",
    "\n",
    "Episode 937, BlackLoss: 2.8184149265289307\n",
    "\n",
    "Episode 941, BlackLoss: 2.8245623111724854\n",
    "\n",
    "Episode 946, BlackLoss: 2.8251187801361084\n",
    "\n",
    "Episode 950, BlackLoss: 2.8151679039001465\n",
    "\n",
    "Episode 954, BlackLoss: 2.8054418563842773\n",
    "\n",
    "Episode 959, BlackLoss: 2.806480646133423\n",
    "\n",
    "Episode 963, BlackLoss: 2.7965075969696045\n",
    "\n",
    "Episode 967, BlackLoss: 2.797408103942871\n",
    "\n",
    "Episode 971, BlackLoss: 2.7875096797943115\n",
    "\n",
    "Episode 976, BlackLoss: 2.7776401042938232\n",
    "\n",
    "Episode 980, BlackLoss: 2.778292417526245\n",
    "\n",
    "Episode 984, BlackLoss: 2.768510580062866\n",
    "\n",
    "Episode 989, BlackLoss: 2.7690961360931396\n",
    "\n",
    "Episode 993, BlackLoss: 2.7593724727630615\n",
    "\n",
    "Episode 997, BlackLoss: 2.760408878326416\n",
    "\n",
    "save \n",
    "Episode 1002, BlackLoss: 2.7513041496276855\n",
    "\n",
    "Episode 1006, BlackLoss: 2.7519822120666504\n",
    "\n",
    "Episode 1010, BlackLoss: 2.762232780456543\n",
    "\n",
    "Episode 1015, BlackLoss: 2.7732577323913574\n",
    "\n",
    "Episode 1019, BlackLoss: 2.773662567138672\n",
    "\n",
    "Episode 1023, BlackLoss: 2.764507532119751\n",
    "\n",
    "Episode 1027, BlackLoss: 2.755241870880127\n",
    "\n",
    "Episode 1032, BlackLoss: 2.7457995414733887\n",
    "\n",
    "Episode 1036, BlackLoss: 2.736433982849121\n",
    "\n",
    "Episode 1040, BlackLoss: 2.727330446243286\n",
    "\n",
    "Episode 1045, BlackLoss: 2.7186439037323\n",
    "\n",
    "Episode 1049, BlackLoss: 2.70951771736145\n",
    "\n",
    "Episode 1053, BlackLoss: 2.7300026416778564\n",
    "\n",
    "Episode 1057, BlackLoss: 2.7310750484466553\n",
    "\n",
    "Episode 1062, BlackLoss: 2.722191095352173\n",
    "\n",
    "Episode 1066, BlackLoss: 2.7130563259124756\n",
    "\n",
    "Episode 1070, BlackLoss: 2.7043793201446533\n",
    "\n",
    "Episode 1075, BlackLoss: 2.6956512928009033\n",
    "\n",
    "Episode 1079, BlackLoss: 2.6964099407196045\n",
    "\n",
    "Episode 1083, BlackLoss: 2.702540397644043\n",
    "\n",
    "Episode 1088, BlackLoss: 2.703860282897949\n",
    "\n",
    "Episode 1092, BlackLoss: 2.7050259113311768\n",
    "\n",
    "Episode 1096, BlackLoss: 2.696260452270508\n",
    "\n",
    "Episode 1100, BlackLoss: 2.6879215240478516\n",
    "\n",
    "save \n",
    "Episode 1105, BlackLoss: 2.679471492767334\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepQResNet import DQN\n",
    "import random\n",
    "env.metadata['autoplay'] = True\n",
    "env.metadata['render_fps'] = 1500000\n",
    "obs, reward, bdone, _, info = env.reset()\n",
    "\n",
    "Blackdqn = DQN(state_shape,env.action_space.n)\n",
    "version = -1\n",
    "# Blackdqn.load( f\"model/Greedy/BlackModel_{version}.weights.h5\")\n",
    "BlackmodelCount = version +1\n",
    "def GetPolicy(bdone,wdone,turn,env,obs,actions):\n",
    "    if(not actions):\n",
    "        return None\n",
    "    if(turn==1):\n",
    "        if(bdone):\n",
    "            return None\n",
    "        return Blackdqn.BehaviorPolicy(env,obs,actions)\n",
    "    else:\n",
    "        if(wdone):\n",
    "            return None\n",
    "        return random.choice(actions)\n",
    "def InsertBuffer(turn,oldobs, action, reward,obs,done,actions):\n",
    "    if(turn==1):\n",
    "        Blackdqn.InsertBuffer(oldobs, action, reward,obs,done,actions)\n",
    "for episode in range(1,10000):\n",
    "    bdone = False\n",
    "    wdone = False\n",
    "    obs, reward, done, _, info = env.reset()\n",
    "    steps = 0\n",
    "    while (not bdone) or (not wdone):\n",
    "        actions = info['action']\n",
    "        turn = info['turn']\n",
    "        oldobs = obs\n",
    "        action = GetPolicy(bdone,wdone,turn,env,obs,actions)\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        if done:\n",
    "            if info['turn'] ==2:\n",
    "                wdone = True\n",
    "            else:\n",
    "                bdone = True\n",
    "\n",
    "        if(action is not None):\n",
    "            InsertBuffer(turn,oldobs, action, reward,obs,done,actions)\n",
    "        if(steps>100):\n",
    "            print(\"wtf?\")\n",
    "        steps += 1\n",
    "    blakloss = Blackdqn.train()\n",
    "    whiteloss = Whitedqn.train()\n",
    "    if blakloss is not None:\n",
    "        print(f\"Episode {episode + 1}, BlackLoss: {blakloss}\\n\")\n",
    "        Blackdqn.update_target_model()\n",
    "    if(episode % 100 == 0):\n",
    "        print('save ')\n",
    "        Blackdqn.save(f\"model/BlackModel_{BlackmodelCount}.weights.h5\")\n",
    "        BlackmodelCount+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behavior 정책을 사용하여 학습 진행 \n",
    "\n",
    "UCT 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepQResNet import DQN\n",
    "import random\n",
    "env.metadata['autoplay'] = True\n",
    "env.metadata['render_fps'] = 1500000\n",
    "obs, reward, bdone, _, info = env.reset()\n",
    "\n",
    "Blackdqn = DQN(state_shape,env.action_space.n)\n",
    "version = -1\n",
    "#Blackdqn.load( f\"model/UCT/BlackModel_{version}.weights.h5\")\n",
    "BlackmodelCount = version +1\n",
    "def GetPolicy(bdone,wdone,turn,env,obs,actions):\n",
    "    if(not actions):\n",
    "        return None\n",
    "    if(turn==1):\n",
    "        if(bdone):\n",
    "            return None\n",
    "        return Blackdqn.BehaviorPolicy(env,obs,actions)\n",
    "    else:\n",
    "        if(wdone):\n",
    "            return None\n",
    "        return random.choice(actions)\n",
    "def InsertBuffer(turn,oldobs, action, reward,obs,done,actions):\n",
    "    if(turn==1):\n",
    "        Blackdqn.InsertBuffer(oldobs, action, reward,obs,done,actions)\n",
    "for episode in range(1,10000):\n",
    "    bdone = False\n",
    "    wdone = False\n",
    "    obs, reward, done, _, info = env.reset()\n",
    "    steps = 0\n",
    "    while (not bdone) or (not wdone):\n",
    "        actions = info['action']\n",
    "        turn = info['turn']\n",
    "        oldobs = obs\n",
    "        action = GetPolicy(bdone,wdone,turn,env,obs,actions)\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        if done:\n",
    "            if info['turn'] ==2:\n",
    "                wdone = True\n",
    "            else:\n",
    "                bdone = True\n",
    "        if(action is not None):\n",
    "            InsertBuffer(turn,oldobs, action, reward,obs,done,actions)\n",
    "        if(steps>100):\n",
    "            print(\"wtf?\")\n",
    "        steps += 1\n",
    "    blakloss = Blackdqn.train()\n",
    "    if blakloss is not None:\n",
    "        print(f\"Episode {episode + 1}, BlackLoss: {blakloss}\\n\")\n",
    "        Blackdqn.update_target_model()\n",
    "    if(episode % 100 == 0):\n",
    "        print('save ')\n",
    "        Blackdqn.save(f\"model/UCT/BlackModel_{BlackmodelCount}.weights.h5\")\n",
    "        BlackmodelCount+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 경쟁을 통해 학습\n",
    "\n",
    "white , black dqn 동시 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPolicy(bdone,wdone,turn,env,obs,actions):\n",
    "    if(not actions):\n",
    "        return None\n",
    "    if(turn==1):\n",
    "        if(bdone):\n",
    "            return None\n",
    "        return Blackdqn.BehaviorPolicy(env,obs,actions)\n",
    "    else:\n",
    "        if(wdone):\n",
    "            return None\n",
    "        return Whitedqn.BehaviorPolicy(env,obs,actions)\n",
    "def InsertBuffer(turn,oldobs, action, reward,obs,done,actions):\n",
    "    if(turn==1):\n",
    "        Blackdqn.InsertBuffer(oldobs, action, reward,obs,done,actions)\n",
    "    else:\n",
    "        Whitedqn.InsertBuffer(oldobs, action, reward,obs,done,actions)\n",
    "\n",
    "env.metadata['autoplay'] = True\n",
    "env.metadata['render_fps'] = 1500000\n",
    "obs, reward, bdone, _, info = env.reset()\n",
    "state_shape = (8, 8, 1)  # Adding the channel dimension\n",
    "Blackdqn = DQN(state_shape,env.action_space.n)\n",
    "Whitedqn = DQN(state_shape,env.action_space.n)\n",
    "\n",
    "version = -1\n",
    "# Blackdqn.load( f\"model/BlackModel_{version}.weights.h5\")\n",
    "# Whitedqn.load(f\"model/WhiteModel_{version}.weights.h5\")\n",
    "BlackmodelCount = version +1\n",
    "WhitemodelCount = version +1\n",
    "\n",
    "for episode in range(1,10000):\n",
    "    bdone = False\n",
    "    wdone = False\n",
    "    obs, reward, done, _, info = env.reset()\n",
    "    steps = 0\n",
    "    while (not bdone) or (not wdone):\n",
    "        actions = info['action']\n",
    "        turn = info['turn']\n",
    "        oldobs = obs\n",
    "        action = GetPolicy(bdone,wdone,turn,env,obs,actions)\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        if done:\n",
    "            if info['turn'] ==2:\n",
    "                wdone = True\n",
    "            else:\n",
    "                bdone = True\n",
    "        if(action is not None):\n",
    "            InsertBuffer(turn,oldobs, action, reward,obs,done,actions)\n",
    "        if(steps>100):\n",
    "            print(\"wtf?\")\n",
    "        steps += 1\n",
    "    blakloss = Blackdqn.train()\n",
    "    whiteloss = Whitedqn.train()\n",
    "    if blakloss is not None:\n",
    "        print(f\"Episode {episode + 1}, BlackLoss: {blakloss}\\n\")\n",
    "        Blackdqn.update_target_model()\n",
    "    if whiteloss is not None:\n",
    "        print(f\"Episode {episode + 1}, WhiteLoss: {whiteloss}\\n\")\n",
    "        Whitedqn.update_target_model()\n",
    "    if(episode % 100 == 0):\n",
    "        print('save ')\n",
    "        Whitedqn.save(f\"model/WhiteModel_{WhitemodelCount}.weights.h5\")\n",
    "        Blackdqn.save(f\"model/BlackModel_{BlackmodelCount}.weights.h5\")\n",
    "        BlackmodelCount+=1\n",
    "        WhitemodelCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zx288\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.simulateNextState to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.simulateNextState` for environment variables or `env.get_wrapper_attr('simulateNextState')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def GetPolicy(bdone,wdone,turn,env,obs,actions):\n",
    "    if(not actions):\n",
    "        return None\n",
    "    if(turn==1):\n",
    "        if(bdone):\n",
    "            return None  \n",
    "        if(BlackPlay):\n",
    "            return None\n",
    "        return Blackdqn.BehaviorPolicy(env,obs,actions)\n",
    "    else:\n",
    "        if(wdone):\n",
    "            return None\n",
    "        if(not BlackPlay):\n",
    "            return None\n",
    "        return Whitedqn.BehaviorPolicy(env,obs,actions)\n",
    "    \n",
    "\n",
    "env.metadata['render_fps'] = 60\n",
    "Blackdqn = DQN(state_shape,env.action_space.n)\n",
    "Whitedqn = DQN(state_shape,env.action_space.n)\n",
    "bdone = False\n",
    "wdone = False\n",
    "BlackPlay = True\n",
    "env.metadata['autoplay'] = not BlackPlay\n",
    "obs, reward, done, _, info = env.reset()\n",
    "\n",
    "\n",
    "while (not bdone) or (not wdone):\n",
    "    actions = info['action']\n",
    "    turn = info['turn']\n",
    "    oldobs = obs\n",
    "    time.sleep(0.5)\n",
    "    action = GetPolicy(bdone,wdone,turn,env,obs,actions)\n",
    "    obs, reward, done, _, info = env.step(action)\n",
    "    env.metadata['autoplay'] = not env.metadata['autoplay']\n",
    "    env.render()\n",
    "    if done:\n",
    "        if info['turn'] ==2:\n",
    "            wdone = True\n",
    "        else:\n",
    "            bdone = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
